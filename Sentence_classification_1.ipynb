{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence classification by MorphConv\n",
    "Implementation of [Convolutional Neural Networks for Sentence Classification](https://arxiv.org/abs/1408.5882) to classify sentiment of movie review\n",
    "\n",
    "### Explanation of this notebook\n",
    "* Dataset : [Naver sentiment movie corpus v1.0](https://github.com/e9t/nsmc)\n",
    "    + train, validation : splitting `ratings_train.txt` (150k reviews) for train (120k reviews) and validation (30k reviews)\n",
    "    + test : `ratings_test.txt` (50k reviews)\n",
    "* Preprocessing\n",
    "    + Morphological analysis by Mecab wrapped by [konlpy](http://konlpy.org/en/latest/)\n",
    "    + Using [FastText](https://arxiv.org/abs/1607.04606) embedding by [gluonnlp package](https://gluon-nlp.mxnet.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import khaiii\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "ratings_train = pd.read_csv('data/ratings_train.txt', sep = '\\t')[['document', 'label']]\n",
    "ratings_test = pd.read_csv('data/ratings_test.txt', sep = '\\t')[['document', 'label']]\n",
    "\n",
    "# ratings, ratings_tst의 document column에 nan 값이 있으므로 이를 빈 문자열로 대체\n",
    "print(sum(ratings_train.document.isna()), sum(ratings_test.document.isna()))\n",
    "\n",
    "ratings_train.document[ratings_train.document.isna()] = ''\n",
    "ratings_test.document[ratings_test.document.isna()] = ''\n",
    "\n",
    "print(sum(ratings_train.document.isna()), sum(ratings_test.document.isna()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use khaiii for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_morphs(text):\n",
    "#     tag_list = ['NNG', 'NNP', 'NNB', 'NP', 'NR', 'VV', 'VA', \n",
    "#             'VX', 'VCP', 'VCN', 'MM', 'MAG', 'MAJ', 'IC']\n",
    "    tag_list = ['NNG', 'NNP', 'NP', 'NR', 'VV', 'VA', 'VX', 'VCP', 'VCN',\n",
    "                'MM', 'MAG', 'MAJ', 'IC', 'SN', 'SW', 'SWK', 'SO', 'XR',\n",
    "                'SH', 'SL', 'ZN', 'ZV', 'SP', 'SE']\n",
    "\n",
    "#     text = re.sub('[^ㅎㅎ|^^|ㅡ|\\-|~|;|♥|♡|★|ㅠ|ㅜ|a-z|A-Z|ㄱ-ㅎ|가-힣|\\'|\\\"|\\,|\\.|\\!|\\?|\\d]', \n",
    "#                   ' ', text)\n",
    "    text = re.sub('(ㅡ.ㅡ|-.-)', ' ㅡㅡ ', text)\n",
    "    text = re.sub('(ㅡ|-){2,}', ' ㅡㅡ ', text)\n",
    "    text = re.sub('(ㄱ-ㅎ|^){2,}', ' \\g<1>\\g<1> ', text)\n",
    "    text = re.sub('(♥|♡)+', ' ♥♥ ', text)\n",
    "    text = re.sub('(★|;|~)+', ' \\g<1>\\g<1> ', text)\n",
    "    text = re.sub('[ㅠ|ㅜ]+', ' ㅠ ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    \n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return ''\n",
    "\n",
    "    result = api.analyze(text) \n",
    "    result_word = [m.lex+'다' if m.tag.startswith('V') else m.lex\n",
    "                       for word in result\n",
    "                          for m in word.morphs\n",
    "                            if m.tag in tag_list]\n",
    "    result_words = '+'.join(result_word)\n",
    "    result_words = result_words.replace('^+^', '^^')\n",
    "    result_words = result_words.replace('ㅠ', 'ㅠㅠ')\n",
    "    return result_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: /usr/local/lib/python3.6/dist-packages/khaiii\n"
     ]
    }
   ],
   "source": [
    "api = khaiii.KhaiiiApi()\n",
    "api.open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make train morphs......\n",
      "Make test morphs......\n",
      "CPU times: user 3min 25s, sys: 400 ms, total: 3min 26s\n",
      "Wall time: 3min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train\n",
    "print('Make train morphs......')\n",
    "ratings_train['morphs'] = ratings_train['document'].apply(make_morphs)\n",
    "\n",
    "# test\n",
    "print('Make test morphs......')\n",
    "ratings_test['morphs'] = ratings_test['document'].apply(make_morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_train.to_csv('data/ratings_train_khaiii.txt', sep='\\t', index=False)\n",
    "ratings_test.to_csv('data/ratings_test_khaiii.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: /usr/local/lib/python3.6/dist-packages/khaiii\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['뻔 / NNB', '하 / XSA', '여 / EC']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## khaiii test\n",
    "\n",
    "api = khaiii.KhaiiiApi()\n",
    "api.open()\n",
    "\n",
    "text='뻔해'\n",
    "# text = re.sub('[^ㄱ-ㅎ|ㅏ-ㅣ|가-힣]', ' ', text)\n",
    "# text = re.sub('\\s+', ' ', text)\n",
    "\n",
    "result_word = [m.lex+' / '+m.tag for word in api.analyze(text)\n",
    "                      for m in word.morphs]\n",
    "\n",
    "# result_word = make_morphs(text)\n",
    "\n",
    "api.close()\n",
    "\n",
    "result_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 29\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv('data/ratings_train_khaiii.txt', sep = '\\t')[['morphs', 'label']]\n",
    "ratings_test = pd.read_csv('data/ratings_test_khaiii.txt', sep = '\\t')[['morphs', 'label']]\n",
    "\n",
    "# ratings, ratings_tst의 document column에 nan 값이 있으므로 이를 빈 문자열로 대체\n",
    "print(sum(ratings.morphs.isna()), sum(ratings_test.morphs.isna()))\n",
    "\n",
    "ratings.morphs[ratings.morphs.isna()] = ''\n",
    "ratings_test.morphs[ratings_test.morphs.isna()] = ''\n",
    "\n",
    "print(sum(ratings_train.morphs.isna()), sum(ratings_test.morphs.isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 2) (30000, 2) (50000, 2)\n"
     ]
    }
   ],
   "source": [
    "val_indices = np.random.choice(a = range(ratings.shape[0]), size = int(ratings.shape[0] * .2),\n",
    "                               replace = False)\n",
    "train_indices = np.delete(arr = range(ratings.shape[0]), obj = val_indices, axis = 0)\n",
    "\n",
    "ratings_train = ratings.iloc[train_indices,:]\n",
    "ratings_val = ratings.iloc[val_indices,:]\n",
    "\n",
    "print(ratings_train.shape, ratings_val.shape, ratings_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_word(text):\n",
    "#     return text.split('+')\n",
    "    return [word for word in text.split('+') if len(word) >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make train data......\n",
      "Make validation data......\n",
      "Make test data......\n",
      "CPU times: user 824 ms, sys: 40.1 ms, total: 864 ms\n",
      "Wall time: 866 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train\n",
    "print('Make train data......')\n",
    "x_train = ratings_train.morphs.apply(split_word).tolist()\n",
    "y_train = ratings_train.label.tolist()\n",
    "\n",
    "# validation\n",
    "print('Make validation data......')\n",
    "x_val = ratings_val.morphs.apply(split_word).tolist()\n",
    "y_val = ratings_val.label.tolist()\n",
    "\n",
    "# test\n",
    "print('Make test data......')\n",
    "x_test = ratings_test.morphs.apply(split_word).tolist()\n",
    "y_test = ratings_test.label.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building vocabulary and connecting vocabulary with fasttext embedding\n",
    "https://gluon-nlp.mxnet.io/examples/word_embedding/word_embedding.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset 기반으로 vocab 생성\n",
    "counter = nlp.data.count_tokens(itertools.chain.from_iterable([c for c in x_train]))\n",
    "vocab = nlp.Vocab(counter,bos_token=None, eos_token=None, min_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'더빙': 307,\n",
       "         '진짜': 4757,\n",
       "         '짜증': 854,\n",
       "         '나다': 3687,\n",
       "         '목소리': 244,\n",
       "         '스터': 28,\n",
       "         '보다': 33349,\n",
       "         '초딩': 275,\n",
       "         '영화줄': 2,\n",
       "         '...': 10492,\n",
       "         '연기': 4972,\n",
       "         '가볍다': 284,\n",
       "         '않다': 6128,\n",
       "         '너무재밓': 1,\n",
       "         '을추천': 1,\n",
       "         '교도소': 6,\n",
       "         '이야기': 1509,\n",
       "         '이다': 48520,\n",
       "         '솔직히': 798,\n",
       "         '재미': 2707,\n",
       "         '없다': 11764,\n",
       "         '평점': 4505,\n",
       "         '조정': 35,\n",
       "         '사이몬': 1,\n",
       "         '페그': 2,\n",
       "         '익살': 11,\n",
       "         '돋보이다': 173,\n",
       "         '영화': 37409,\n",
       "         '스파이더맨': 39,\n",
       "         '늙다': 147,\n",
       "         '하다': 16959,\n",
       "         '스트': 61,\n",
       "         '너무나': 558,\n",
       "         '이쁘다': 610,\n",
       "         '보이다': 1934,\n",
       "         '걸음마': 2,\n",
       "         '떼다': 103,\n",
       "         '초등학교': 88,\n",
       "         '학년생': 1,\n",
       "         '용영화': 10,\n",
       "         'ㅋㅋㅋ': 1107,\n",
       "         '..': 16829,\n",
       "         '.별반개': 3,\n",
       "         '아깝다': 2906,\n",
       "         '반개': 113,\n",
       "         '욕나': 62,\n",
       "         '오다': 2627,\n",
       "         '이응경': 7,\n",
       "         '길용우': 4,\n",
       "         '생활': 80,\n",
       "         '이몇': 1,\n",
       "         '정말': 7100,\n",
       "         '발로': 23,\n",
       "         '그것': 725,\n",
       "         '납치': 29,\n",
       "         '감금': 6,\n",
       "         '만반': 1,\n",
       "         '복반복': 1,\n",
       "         '이드라': 16,\n",
       "         '가족도': 1,\n",
       "         '사람': 3447,\n",
       "         '모엿네': 1,\n",
       "         '액션': 1822,\n",
       "         '있다': 13469,\n",
       "         '왜케': 78,\n",
       "         '낮다': 921,\n",
       "         '헐리우드식': 9,\n",
       "         '화려': 268,\n",
       "         '너무': 7698,\n",
       "         '길들이다': 13,\n",
       "         '지다': 4546,\n",
       "         '볼때': 91,\n",
       "         '눈물': 867,\n",
       "         '죽다': 1025,\n",
       "         '90': 291,\n",
       "         '향수자극': 1,\n",
       "         '허진호': 5,\n",
       "         '감성절제멜': 1,\n",
       "         '달인': 6,\n",
       "         '~~': 8592,\n",
       "         '울다': 813,\n",
       "         '손들다': 5,\n",
       "         '횡단보도': 1,\n",
       "         '건널': 1,\n",
       "         '뛰쳐나다': 3,\n",
       "         '이범수': 32,\n",
       "         '드럽다': 170,\n",
       "         '못해': 8,\n",
       "         '담백': 58,\n",
       "         '깔끔': 129,\n",
       "         '좋다': 9295,\n",
       "         '신문': 7,\n",
       "         '기사': 45,\n",
       "         '자꾸': 188,\n",
       "         '잊어버리다': 9,\n",
       "         '취향': 168,\n",
       "         '존중': 27,\n",
       "         '내생': 85,\n",
       "         '극장': 634,\n",
       "         '가장': 1051,\n",
       "         '노잼': 367,\n",
       "         '노감': 1,\n",
       "         '동임': 1,\n",
       "         '스토리': 3741,\n",
       "         '어거지다': 4,\n",
       "         '감동': 3482,\n",
       "         '어거지': 47,\n",
       "         '매번': 45,\n",
       "         '긴장': 140,\n",
       "         '재밋음': 51,\n",
       "         'ㅠㅠ': 4957,\n",
       "         '웃기다': 1162,\n",
       "         '바스코': 5,\n",
       "         '이기다': 118,\n",
       "         '락스코': 1,\n",
       "         '아이돌': 86,\n",
       "         '깔다': 36,\n",
       "         '그냥': 3000,\n",
       "         '까다': 125,\n",
       "         '고싶다': 11,\n",
       "         '달다': 237,\n",
       "         '굿바이': 13,\n",
       "         '레닌': 5,\n",
       "         '표절': 134,\n",
       "         '이해': 1393,\n",
       "         '가다': 3448,\n",
       "         '재미없다': 2469,\n",
       "         '이것': 4021,\n",
       "         '깨알': 37,\n",
       "         '캐스팅': 412,\n",
       "         '질퍽': 3,\n",
       "         '산뜻': 12,\n",
       "         '내용': 2942,\n",
       "         '구성': 397,\n",
       "         '버무러다': 2,\n",
       "         '깨알일드': 1,\n",
       "         '♥♥': 1041,\n",
       "         '심오': 70,\n",
       "         '학생': 94,\n",
       "         '선생': 153,\n",
       "         '놀아나다': 14,\n",
       "         '절대': 422,\n",
       "         '아니다': 4988,\n",
       "         '웃다': 771,\n",
       "         '가능': 277,\n",
       "         '지루': 3219,\n",
       "         '같다': 6181,\n",
       "         '음식': 56,\n",
       "         '바베트': 2,\n",
       "         '만찬': 4,\n",
       "         '차이남': 1,\n",
       "         '보는': 256,\n",
       "         ';;': 2974,\n",
       "         '볼게': 4,\n",
       "         '별로': 916,\n",
       "         '안나오다': 163,\n",
       "         '핀란드': 4,\n",
       "         '풍경': 96,\n",
       "         '구경': 40,\n",
       "         '안나다': 88,\n",
       "         '평범': 256,\n",
       "         '수작': 491,\n",
       "         '말씀': 47,\n",
       "         '드리다': 226,\n",
       "         '짜르다': 4,\n",
       "         '그래서': 309,\n",
       "         '납득': 42,\n",
       "         '그다': 712,\n",
       "         '러다': 353,\n",
       "         '카밀': 7,\n",
       "         '라벨': 2,\n",
       "         '발연기': 285,\n",
       "         '재밋는뎅': 1,\n",
       "         '센스': 68,\n",
       "         '연출력': 223,\n",
       "         '탁월': 47,\n",
       "         '향수': 49,\n",
       "         '엄포스': 3,\n",
       "         '위력': 10,\n",
       "         '다시': 1823,\n",
       "         '깨닫다': 140,\n",
       "         '주다': 7403,\n",
       "         '꽃검사': 1,\n",
       "         '완전': 1794,\n",
       "         '명품드': 5,\n",
       "         '재밌다': 4459,\n",
       "         '별점': 341,\n",
       "         '왜이리': 155,\n",
       "         '기대': 1681,\n",
       "         '죄인': 5,\n",
       "         '....': 3101,\n",
       "         '패션': 31,\n",
       "         '대하다': 1145,\n",
       "         '열정': 119,\n",
       "         '안나': 96,\n",
       "         '의다': 7,\n",
       "         '투어': 5,\n",
       "         '이틀리': 5,\n",
       "         '대체': 365,\n",
       "         '정신': 418,\n",
       "         '장애': 49,\n",
       "         '틱장': 2,\n",
       "         '허허': 38,\n",
       "         '원작가': 3,\n",
       "         '나가다': 328,\n",
       "         '유령': 35,\n",
       "         '재미있다': 4716,\n",
       "         '포스터': 397,\n",
       "         '관객': 488,\n",
       "         '114': 2,\n",
       "         '이렇다': 1982,\n",
       "         '저평': 15,\n",
       "         '받다': 1504,\n",
       "         '모르다': 2201,\n",
       "         '알바생': 5,\n",
       "         '무섭다': 850,\n",
       "         '운거': 35,\n",
       "         '하나': 1426,\n",
       "         '별싱다': 1,\n",
       "         '내ㅇ시간': 1,\n",
       "         '낚임': 23,\n",
       "         '에속지마': 2,\n",
       "         '시다': 191,\n",
       "         '길시간낭비': 1,\n",
       "         '돈낭비임': 2,\n",
       "         '리얼리티': 44,\n",
       "         '뛰어나다': 178,\n",
       "         '크다': 707,\n",
       "         '공감': 683,\n",
       "         '민기캐릭터': 1,\n",
       "         '정신의학상': 1,\n",
       "         '분노': 128,\n",
       "         '조절장애': 3,\n",
       "         '초기': 18,\n",
       "         '증상': 3,\n",
       "         '툭하면': 9,\n",
       "         '패고': 4,\n",
       "         '욕하다': 151,\n",
       "         '물건': 19,\n",
       "         '파손': 2,\n",
       "         '조금': 639,\n",
       "         '오바': 49,\n",
       "         '초반': 421,\n",
       "         '신선': 475,\n",
       "         '갈수록': 72,\n",
       "         '민기': 17,\n",
       "         '상태': 71,\n",
       "         '공감불가': 2,\n",
       "         '마이너': 23,\n",
       "         '뮤비': 12,\n",
       "         '수준': 948,\n",
       "         '북한': 107,\n",
       "         '이런': 3056,\n",
       "         '만들다': 4953,\n",
       "         '대다': 317,\n",
       "         '데너리스': 1,\n",
       "         '르엔': 1,\n",
       "         '용의주인': 1,\n",
       "         '되다': 4780,\n",
       "         '싶다': 3951,\n",
       "         '이랑': 15,\n",
       "         '근친상간': 1,\n",
       "         '다니다': 119,\n",
       "         '소설': 338,\n",
       "         '멋지다': 805,\n",
       "         '이메': 1,\n",
       "         '라니스터': 3,\n",
       "         '드라마속': 8,\n",
       "         '드래곤': 12,\n",
       "         '웃음': 464,\n",
       "         '감독': 2976,\n",
       "         '토르': 20,\n",
       "         '다크': 10,\n",
       "         '월드': 19,\n",
       "         '말다': 1768,\n",
       "         '잡수다': 4,\n",
       "         '기본': 126,\n",
       "         '선방': 3,\n",
       "         '영혼': 80,\n",
       "         '어루만지다': 8,\n",
       "         '거칠다': 27,\n",
       "         '세상사': 6,\n",
       "         '잠시': 55,\n",
       "         '잊다': 443,\n",
       "         '동화': 172,\n",
       "         '행복': 502,\n",
       "         '르다': 520,\n",
       "         '작은고추': 1,\n",
       "         '매운맛': 6,\n",
       "         '포퐁저': 1,\n",
       "         '콩진호': 4,\n",
       "         '가슴': 902,\n",
       "         '리다': 1010,\n",
       "         '드라마': 2911,\n",
       "         '자체': 800,\n",
       "         '최고': 4800,\n",
       "         '심한영화': 2,\n",
       "         '백봉기': 1,\n",
       "         '나오다': 4080,\n",
       "         '그대로': 248,\n",
       "         '들어맞다': 8,\n",
       "         '예측': 43,\n",
       "         '카리스마': 85,\n",
       "         '악역': 136,\n",
       "         '함속': 7,\n",
       "         '녹다': 52,\n",
       "         '들다': 2244,\n",
       "         '일상': 137,\n",
       "         '밋밋': 106,\n",
       "         '사랑': 2473,\n",
       "         '가슴속': 25,\n",
       "         '온감정': 1,\n",
       "         '헤다': 11,\n",
       "         '집다': 33,\n",
       "         '놓다': 951,\n",
       "         '요정': 10,\n",
       "         '많다': 2030,\n",
       "         '다큐': 281,\n",
       "         '우리나라': 461,\n",
       "         '슬프다': 814,\n",
       "         '현대사': 10,\n",
       "         '단면': 13,\n",
       "         '깊이': 156,\n",
       "         '생각': 3896,\n",
       "         '사죄': 4,\n",
       "         '바로': 271,\n",
       "         '잡다': 376,\n",
       "         '위하다': 813,\n",
       "         '노력': 220,\n",
       "         '듣다': 444,\n",
       "         '보도': 10,\n",
       "         '연맹': 1,\n",
       "         '민간인': 20,\n",
       "         '학살': 36,\n",
       "         '이정': 212,\n",
       "         '명백': 13,\n",
       "         '살인': 131,\n",
       "         '살인자': 36,\n",
       "         '어디': 740,\n",
       "         '예전': 376,\n",
       "         '작품': 2208,\n",
       "         '캐릭터': 743,\n",
       "         '에피소드': 99,\n",
       "         '재탕': 41,\n",
       "         '삼탕': 5,\n",
       "         '골우리다': 1,\n",
       "         '먹다': 811,\n",
       "         '우리': 980,\n",
       "         '시청': 340,\n",
       "         '아예안': 1,\n",
       "         '이제': 843,\n",
       "         '70': 135,\n",
       "         '중반': 154,\n",
       "         '120': 27,\n",
       "         '부작': 61,\n",
       "         '김남길': 17,\n",
       "         '백점': 10,\n",
       "         '연기력': 787,\n",
       "         '몰입도': 235,\n",
       "         '불구': 116,\n",
       "         '손예진': 15,\n",
       "         '비슷': 312,\n",
       "         '노래': 584,\n",
       "         '실력': 111,\n",
       "         '뽑다': 94,\n",
       "         '맞다': 925,\n",
       "         '박시환': 13,\n",
       "         'mama': 1,\n",
       "         '망신': 14,\n",
       "         '일본영': 175,\n",
       "         '다이런': 3,\n",
       "         '이틀': 14,\n",
       "         '근데': 671,\n",
       "         '넣다': 270,\n",
       "         '조작': 79,\n",
       "         '열리다': 23,\n",
       "         '활짝': 6,\n",
       "         '아무': 304,\n",
       "         '들어가다': 182,\n",
       "         '문자': 16,\n",
       "         '비번이': 2,\n",
       "         '걸리다': 135,\n",
       "         'ㅋㅋ': 2556,\n",
       "         '그런': 471,\n",
       "         '억지': 575,\n",
       "         '그러다': 997,\n",
       "         '졸작': 403,\n",
       "         '어설프다': 493,\n",
       "         '전개': 1091,\n",
       "         '어이없다': 413,\n",
       "         '결말': 1129,\n",
       "         '부패': 11,\n",
       "         '로마노프': 2,\n",
       "         '왕조': 8,\n",
       "         '기리다': 8,\n",
       "         '온몸': 30,\n",
       "         '항거': 3,\n",
       "         '러시아': 53,\n",
       "         '민중': 9,\n",
       "         '그저': 396,\n",
       "         '폭도': 5,\n",
       "         '무난': 46,\n",
       "         '이이다': 229,\n",
       "         '^^': 2307,\n",
       "         '한국': 1399,\n",
       "         '흥행': 233,\n",
       "         '코드': 109,\n",
       "         '갈등': 99,\n",
       "         '에속': 5,\n",
       "         '화해': 21,\n",
       "         '10': 2907,\n",
       "         '남발': 26,\n",
       "         '뻔다': 156,\n",
       "         '럼먹다': 1,\n",
       "         '엉망진창': 35,\n",
       "         '개진창': 1,\n",
       "         '정말쓰레기': 2,\n",
       "         '진정': 421,\n",
       "         '위대': 165,\n",
       "         '최고임': 76,\n",
       "         '별루': 114,\n",
       "         '내일': 73,\n",
       "         '골깜': 1,\n",
       "         '부라리다': 1,\n",
       "         '쓰러지다': 29,\n",
       "         '성룡영': 21,\n",
       "         '최악': 1638,\n",
       "         '서기': 21,\n",
       "         '가이쁘다': 1,\n",
       "         'ㅋㅋㅋㅋ': 495,\n",
       "         'ㅋ백': 1,\n",
       "         '인공주귀': 1,\n",
       "         '움다': 9,\n",
       "         'ㅋㅋㅋㅋㅋㅋ': 89,\n",
       "         '인상': 457,\n",
       "         '설정': 444,\n",
       "         '새롭다': 384,\n",
       "         '메인': 20,\n",
       "         '차차': 3,\n",
       "         '진심': 657,\n",
       "         '이훨': 2,\n",
       "         '캐스': 6,\n",
       "         '두다': 329,\n",
       "         '잔잔': 671,\n",
       "         '인거': 45,\n",
       "         '노골': 36,\n",
       "         '술광고': 1,\n",
       "         '은은': 26,\n",
       "         '어떻다': 868,\n",
       "         '킬링타임': 132,\n",
       "         '매력': 1038,\n",
       "         'ㅎㅎ': 386,\n",
       "         '음악': 1074,\n",
       "         '완전히': 90,\n",
       "         '빠지다': 748,\n",
       "         '태어나다': 144,\n",
       "         '처음': 1755,\n",
       "         '중간': 700,\n",
       "         ',,,,': 104,\n",
       "         '불륜': 202,\n",
       "         '로맨스': 268,\n",
       "         ',,': 753,\n",
       "         '왕짜증': 11,\n",
       "         '짬뽕': 28,\n",
       "         '믹스': 7,\n",
       "         '음향': 45,\n",
       "         '무다': 360,\n",
       "         '대박': 711,\n",
       "         '기준': 83,\n",
       "         '패널': 7,\n",
       "         '가구': 4,\n",
       "         '머다': 50,\n",
       "         '명작드라마': 1,\n",
       "         '망치다': 279,\n",
       "         '서운': 5,\n",
       "         '몬스터': 18,\n",
       "         '주식회사': 7,\n",
       "         '느리다': 99,\n",
       "         '........': 84,\n",
       "         '쓰레기': 2126,\n",
       "         '중국인': 28,\n",
       "         '특유': 216,\n",
       "         '과장': 118,\n",
       "         '허풍': 4,\n",
       "         '안간힘': 2,\n",
       "         '쓰다': 1422,\n",
       "         '가상': 34,\n",
       "         '고증': 44,\n",
       "         '현실감': 51,\n",
       "         '떨어지다': 616,\n",
       "         '거북': 49,\n",
       "         '도대체': 453,\n",
       "         '스스로': 106,\n",
       "         '과대포장': 8,\n",
       "         '불법': 37,\n",
       "         '체류자': 11,\n",
       "         '때려잡다': 9,\n",
       "         '무슨': 1047,\n",
       "         '우상': 15,\n",
       "         '미국': 472,\n",
       "         '따뜻': 541,\n",
       "         '뭥미': 50,\n",
       "         '삶속': 4,\n",
       "         '주인공': 1394,\n",
       "         '생애': 111,\n",
       "         '전부': 240,\n",
       "         '드러나다': 59,\n",
       "         '아니': 277,\n",
       "         '올레': 13,\n",
       "         '공짜로': 3,\n",
       "         '허다': 203,\n",
       "         '문제': 435,\n",
       "         '가아니다': 14,\n",
       "         '연기자': 177,\n",
       "         '전혀': 734,\n",
       "         '배역': 82,\n",
       "         '어울리다': 269,\n",
       "         '그리고': 1407,\n",
       "         '상대': 57,\n",
       "         '배우': 3022,\n",
       "         '따로': 66,\n",
       "         '노다': 46,\n",
       "         '별로임': 68,\n",
       "         '아들': 237,\n",
       "         '욕심': 69,\n",
       "         '어느': 281,\n",
       "         '제대로': 518,\n",
       "         '......': 284,\n",
       "         '빵점': 79,\n",
       "         '베댓': 8,\n",
       "         '아주': 679,\n",
       "         '잘쓰다': 4,\n",
       "         '모자라다': 71,\n",
       "         '짜릿': 47,\n",
       "         '용기': 90,\n",
       "         '가지다': 570,\n",
       "         '교훈': 296,\n",
       "         '당시': 420,\n",
       "         '상황': 340,\n",
       "         '주제': 340,\n",
       "         '주입식': 3,\n",
       "         '긴장감': 625,\n",
       "         '전하다': 112,\n",
       "         '케이블': 143,\n",
       "         '그만': 241,\n",
       "         'ㅡㅡ': 1367,\n",
       "         '여군': 19,\n",
       "         '잼없다': 152,\n",
       "         '다다': 498,\n",
       "         '재다': 370,\n",
       "         '질리다': 169,\n",
       "         '한석규': 46,\n",
       "         '김혜수': 52,\n",
       "         '많이': 1324,\n",
       "         '라바이러스': 2,\n",
       "         '떠들다': 44,\n",
       "         '보게': 69,\n",
       "         '된영화': 18,\n",
       "         '20': 483,\n",
       "         '믿기다': 79,\n",
       "         '힘다': 98,\n",
       "         '마지': 27,\n",
       "         '후반부': 199,\n",
       "         '살짝': 125,\n",
       "         '아쉽다': 1018,\n",
       "         '시간': 2463,\n",
       "         '지않다': 20,\n",
       "         '은영화': 271,\n",
       "         '떨다': 69,\n",
       "         '용가리': 25,\n",
       "         '짱짱맨': 18,\n",
       "         '다ㅋ': 15,\n",
       "         '감히': 82,\n",
       "         '인생': 956,\n",
       "         '꼽다': 90,\n",
       "         '살다': 1051,\n",
       "         '고민': 149,\n",
       "         '모건': 12,\n",
       "         '프리먼': 10,\n",
       "         '나이': 229,\n",
       "         '여전히': 137,\n",
       "         '작가': 611,\n",
       "         '로임': 8,\n",
       "         '그냥다': 5,\n",
       "         '방송': 319,\n",
       "         '혹시나': 50,\n",
       "         '답없다': 25,\n",
       "         '명작': 1445,\n",
       "         '여운': 749,\n",
       "         '남다': 1374,\n",
       "         '역시': 1468,\n",
       "         '일품': 85,\n",
       "         '맥스': 18,\n",
       "         '죽이다': 565,\n",
       "         '바래다': 35,\n",
       "         '괜찮다': 1395,\n",
       "         '지네': 13,\n",
       "         '안뜨다': 17,\n",
       "         '찍다': 852,\n",
       "         '면상': 14,\n",
       "         '알다': 2777,\n",
       "         '자신': 469,\n",
       "         '어린이': 117,\n",
       "         '좋아하다': 1366,\n",
       "         '내어다': 1,\n",
       "         '동심': 66,\n",
       "         '멀리': 25,\n",
       "         '떠낫': 1,\n",
       "         '크리스토': 8,\n",
       "         '퍼왈츠': 1,\n",
       "         '타란티노': 43,\n",
       "         '조합': 98,\n",
       "         '한국에': 3,\n",
       "         '선유명한편': 1,\n",
       "         '외국': 103,\n",
       "         '상상': 190,\n",
       "         '유명': 195,\n",
       "         '오랜만': 554,\n",
       "         '재밋': 273,\n",
       "         '봤다': 191,\n",
       "         '종방': 4,\n",
       "         '오늘막방': 1,\n",
       "         '잘봤다': 266,\n",
       "         '대본': 76,\n",
       "         '완성': 123,\n",
       "         '느낌': 1520,\n",
       "         '요즘': 605,\n",
       "         '막장': 537,\n",
       "         '지치다': 70,\n",
       "         '백향': 2,\n",
       "         '바다': 126,\n",
       "         '른드라마': 5,\n",
       "         '그리': 137,\n",
       "         '심하다': 299,\n",
       "         'MBC': 39,\n",
       "         '화이팅': 153,\n",
       "         '끝나다': 925,\n",
       "         '때쯤': 9,\n",
       "         '멍하다': 24,\n",
       "         '다보다': 106,\n",
       "         '한마디': 294,\n",
       "         '거임다': 1,\n",
       "         '공유': 50,\n",
       "         '존잘': 5,\n",
       "         '상쾌발': 1,\n",
       "         '껄끄럽다': 6,\n",
       "         '소재': 1067,\n",
       "         '유쾌': 443,\n",
       "         '해설': 15,\n",
       "         '소파': 5,\n",
       "         '치다': 913,\n",
       "         '앉다': 77,\n",
       "         '지키다': 124,\n",
       "         '이유': 565,\n",
       "         '어린': 25,\n",
       "         '로맨틱': 132,\n",
       "         '코미': 54,\n",
       "         '게이물': 7,\n",
       "         '알바는꺼저': 1,\n",
       "         '머이다': 7,\n",
       "         '??': 61,\n",
       "         '스텝': 29,\n",
       "         '꼭두각시': 10,\n",
       "         '아름답다': 1250,\n",
       "         '입다': 163,\n",
       "         '자극': 212,\n",
       "         '익숙': 55,\n",
       "         '현대인': 24,\n",
       "         '힘들다': 637,\n",
       "         '극치': 82,\n",
       "         '굉장히': 258,\n",
       "         '언밸러스': 1,\n",
       "         '뚱뚱': 7,\n",
       "         '못생기다': 59,\n",
       "         '남자': 1049,\n",
       "         '시종일관': 48,\n",
       "         '봐다': 225,\n",
       "         '고역인': 1,\n",
       "         '간간히': 40,\n",
       "         '흘러나오다': 25,\n",
       "         '클래식': 42,\n",
       "         '싫다': 522,\n",
       "         '짜증날정도': 5,\n",
       "         '상당히': 274,\n",
       "         '감동감동': 21,\n",
       "         '안내': 11,\n",
       "         '돼지': 41,\n",
       "         '피먹다': 1,\n",
       "         '닭목': 1,\n",
       "         '따다': 112,\n",
       "         '장면': 1499,\n",
       "         '우웩': 8,\n",
       "         '무당': 8,\n",
       "         '버리다': 1113,\n",
       "         '유치': 836,\n",
       "         '윤종신': 2,\n",
       "         '복귀': 12,\n",
       "         '이하': 188,\n",
       "         '뽑히다': 12,\n",
       "         '가없다': 125,\n",
       "         '참가자': 8,\n",
       "         '따지다': 77,\n",
       "         '심사': 45,\n",
       "         '위원': 29,\n",
       "         '인격': 18,\n",
       "         '쌓다': 15,\n",
       "         '만좀': 9,\n",
       "         '광장': 6,\n",
       "         '옛날': 398,\n",
       "         '어리다': 899,\n",
       "         '시절': 421,\n",
       "         '추억': 437,\n",
       "         '판타지': 223,\n",
       "         '나쁘다': 420,\n",
       "         '금물': 11,\n",
       "         '지옥가': 1,\n",
       "         '기존': 52,\n",
       "         '멜로영화': 41,\n",
       "         '형식': 37,\n",
       "         '탈피': 6,\n",
       "         '감정': 521,\n",
       "         '절제': 51,\n",
       "         '지나치다': 146,\n",
       "         '사랑비': 1,\n",
       "         '서준': 4,\n",
       "         '쏙ㅋㅋ': 1,\n",
       "         '후회도안': 1,\n",
       "         '이영화': 1303,\n",
       "         '남은인': 1,\n",
       "         '야겟': 6,\n",
       "         '젖다': 29,\n",
       "         '음ㅋㅋ': 18,\n",
       "         '각없이': 58,\n",
       "         '추천': 872,\n",
       "         '단순': 244,\n",
       "         '싸이': 53,\n",
       "         '코물': 2,\n",
       "         '벗어나다': 81,\n",
       "         '14': 72,\n",
       "         '다시개': 2,\n",
       "         '허접': 385,\n",
       "         '연잇다': 5,\n",
       "         '귀엽다': 649,\n",
       "         '청춘': 133,\n",
       "         '감성': 263,\n",
       "         '넘쳐나다': 5,\n",
       "         '순간': 223,\n",
       "         '지나가다': 71,\n",
       "         '돌아오다': 95,\n",
       "         '무한': 59,\n",
       "         '젊음': 28,\n",
       "         '개콘': 47,\n",
       "         '코너': 11,\n",
       "         '이안나다': 2,\n",
       "         '사다코': 10,\n",
       "         '서리다': 3,\n",
       "         '우물펀치': 1,\n",
       "         '후세': 9,\n",
       "         '결정': 72,\n",
       "         '계기': 49,\n",
       "         '그시간': 10,\n",
       "         '표현': 682,\n",
       "         '시람': 2,\n",
       "         '생명': 42,\n",
       "         '빼앗다': 10,\n",
       "         '이유등': 1,\n",
       "         '시노': 9,\n",
       "         '출현': 28,\n",
       "         '연극': 65,\n",
       "         '알리다': 238,\n",
       "         '또한': 182,\n",
       "         '얼마나': 407,\n",
       "         '본능': 46,\n",
       "         '히다': 84,\n",
       "         '시랑': 2,\n",
       "         '뻔하다': 65,\n",
       "         '강수연': 14,\n",
       "         '!그다': 1,\n",
       "         '리고': 66,\n",
       "         '최정원': 3,\n",
       "         '신음신': 1,\n",
       "         '가발': 10,\n",
       "         '여정이인상': 1,\n",
       "         '깊다': 571,\n",
       "         '밋다': 237,\n",
       "         '어요ㅋ': 1,\n",
       "         '배두나연기정': 1,\n",
       "         '호기심': 46,\n",
       "         '필요': 1037,\n",
       "         '닥치다': 59,\n",
       "         '각기': 4,\n",
       "         '다른': 764,\n",
       "         '국드라마': 5,\n",
       "         '파다': 51,\n",
       "         '알수없다': 34,\n",
       "         '미묘': 31,\n",
       "         '사로잡다': 22,\n",
       "         '너무너무': 168,\n",
       "         '훈훈': 218,\n",
       "         '이거': 2041,\n",
       "         '응답': 8,\n",
       "         '은지원': 7,\n",
       "         '않앗다': 7,\n",
       "         '배꼽': 41,\n",
       "         '빠질뻔': 2,\n",
       "         '부실': 78,\n",
       "         '네이버': 216,\n",
       "         '믿다': 621,\n",
       "         '장끌': 5,\n",
       "         '로드': 20,\n",
       "         '몰락': 33,\n",
       "         '가져오다': 28,\n",
       "         '오우삼': 24,\n",
       "         '헐리우드': 95,\n",
       "         '언제': 356,\n",
       "         '영웅': 171,\n",
       "         '본색': 36,\n",
       "         '연출': 1352,\n",
       "         '현실': 1159,\n",
       "         '작다': 131,\n",
       "         '설레다': 111,\n",
       "         '학창': 35,\n",
       "         '그때': 237,\n",
       "         '그느낌': 3,\n",
       "         '느끼다': 1746,\n",
       "         '수다': 83,\n",
       "         '대사': 711,\n",
       "         '배경': 462,\n",
       "         '높다': 1004,\n",
       "         '화남': 7,\n",
       "         '더럽다': 441,\n",
       "         '어떤': 340,\n",
       "         '형태': 17,\n",
       "         '닿다': 217,\n",
       "         '허무': 258,\n",
       "         '완벽히': 21,\n",
       "         '영화고': 24,\n",
       "         '영양가': 5,\n",
       "         '이승기': 14,\n",
       "         '조연': 143,\n",
       "         '판의미로': 2,\n",
       "         '동급': 22,\n",
       "         'trash': 8,\n",
       "         'of': 69,\n",
       "         'the': 94,\n",
       "         '제대': 70,\n",
       "         '마음': 1097,\n",
       "         '휴가': 20,\n",
       "         '다녀오다': 36,\n",
       "         '래서': 44,\n",
       "         '살가득': 1,\n",
       "         '비이': 1,\n",
       "         '부엌': 2,\n",
       "         '요리': 64,\n",
       "         '1996': 10,\n",
       "         '나라': 232,\n",
       "         '아직': 852,\n",
       "         '신현준': 29,\n",
       "         '황장': 2,\n",
       "         '전성': 8,\n",
       "         '시대': 533,\n",
       "         '이때': 106,\n",
       "         '댓글': 195,\n",
       "         '한번쯤볼': 1,\n",
       "         '기가차다': 2,\n",
       "         '이게': 36,\n",
       "         '무슨버킷': 1,\n",
       "         '리스트': 22,\n",
       "         '죽기': 6,\n",
       "         '직전': 22,\n",
       "         '소원': 15,\n",
       "         '가보다': 50,\n",
       "         '인걸다': 1,\n",
       "         '감동도': 66,\n",
       "         '버킷리스트': 2,\n",
       "         '발톱': 22,\n",
       "         '못다': 352,\n",
       "         '따라가다': 68,\n",
       "         '는쓰레기': 3,\n",
       "         '완존': 14,\n",
       "         '실망': 751,\n",
       "         '밝다': 59,\n",
       "         '긍정': 26,\n",
       "         '인드라': 2,\n",
       "         '길다': 414,\n",
       "         '오버': 91,\n",
       "         '는연기': 6,\n",
       "         '슬리다': 9,\n",
       "         '게너무표나': 1,\n",
       "         '홍혜정역': 1,\n",
       "         '마도후련': 1,\n",
       "         '기도': 36,\n",
       "         '나머': 40,\n",
       "         '낼월요일': 1,\n",
       "         '해피': 32,\n",
       "         '정치인': 16,\n",
       "         '모순': 31,\n",
       "         '정치': 139,\n",
       "         '대단': 664,\n",
       "         '어렵다': 352,\n",
       "         '전쟁': 498,\n",
       "         '묘사가': 1,\n",
       "         '대희': 1,\n",
       "         '개그콘서트': 4,\n",
       "         '내전': 6,\n",
       "         '콘서트': 26,\n",
       "         '없애주다': 5,\n",
       "         '한물': 12,\n",
       "         '동서양': 6,\n",
       "         '싸움판': 2,\n",
       "         '구만': 3,\n",
       "         '세계': 315,\n",
       "         '최초': 80,\n",
       "         '반공': 5,\n",
       "         '애니매이션': 45,\n",
       "         '역사': 404,\n",
       "         '가치': 247,\n",
       "         '감각': 75,\n",
       "         '시각': 107,\n",
       "         '바라보다': 98,\n",
       "         '다르다': 501,\n",
       "         '느낌의': 1,\n",
       "         '문학': 27,\n",
       "         '엄마': 375,\n",
       "         '무고': 13,\n",
       "         '감옥살이': 1,\n",
       "         '시켜다': 3,\n",
       "         '제발': 428,\n",
       "         '책을보세여': 1,\n",
       "         '미다': 137,\n",
       "         '겁다': 72,\n",
       "         '이따위': 43,\n",
       "         '화가': 50,\n",
       "         '날정': 2,\n",
       "         '어쩌다': 404,\n",
       "         '마디': 51,\n",
       "         '알리시아': 2,\n",
       "         '생생': 91,\n",
       "         '옥소리': 3,\n",
       "         '프로필': 7,\n",
       "         '사진': 75,\n",
       "         '남기': 2,\n",
       "         'ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ': 24,\n",
       "         '아우': 29,\n",
       "         '제맛': 13,\n",
       "         '수없다': 194,\n",
       "         '력다': 1,\n",
       "         '에빠': 3,\n",
       "         '모녀': 9,\n",
       "         '토막살해': 1,\n",
       "         '부성애': 12,\n",
       "         '이되다': 14,\n",
       "         '본인': 113,\n",
       "         '피해자': 87,\n",
       "         '할수': 97,\n",
       "         '묻다': 139,\n",
       "         'OOO': 513,\n",
       "         '아놓다': 89,\n",
       "         '기명작': 1,\n",
       "         '필름': 100,\n",
       "         '점수준': 10,\n",
       "         '매미': 53,\n",
       "         'OO': 712,\n",
       "         '인공': 31,\n",
       "         '안습': 76,\n",
       "         '혀다': 7,\n",
       "         '소리': 406,\n",
       "         '매니': 29,\n",
       "         '저역활분': 1,\n",
       "         '남주': 139,\n",
       "         '훨다': 23,\n",
       "         '들정다': 2,\n",
       "         '적당히': 67,\n",
       "         '뭘전달': 1,\n",
       "         '지모르다': 8,\n",
       "         '오글거리다': 250,\n",
       "         '이상': 1367,\n",
       "         '할머니': 98,\n",
       "         '월래익': 1,\n",
       "         'ㄷㅔ': 1,\n",
       "         '.....': 518,\n",
       "         '모든': 666,\n",
       "         '부족': 623,\n",
       "         '50': 123,\n",
       "         '12': 148,\n",
       "         '기억': 1235,\n",
       "         '진개': 2,\n",
       "         '천카': 1,\n",
       "         '이름': 345,\n",
       "         '정은': 3,\n",
       "         '언니': 91,\n",
       "         '부르다': 209,\n",
       "         '마지막회': 55,\n",
       "         '즐겁다': 346,\n",
       "         '트로트': 3,\n",
       "         '연인': 59,\n",
       "         '망다': 60,\n",
       "         '아이': 986,\n",
       "         '시선': 134,\n",
       "         '내내': 698,\n",
       "         ...})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading fasttext embedding \n",
    "fasttext_simple = nlp.embedding.create('fasttext', source='wiki.ko')\n",
    "\n",
    "# vocab에 embedding 연결\n",
    "vocab.set_embedding(fasttext_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.51 s, sys: 24 ms, total: 2.53 s\n",
      "Wall time: 2.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# final preprocessing\n",
    "\n",
    "X_tr = list(map(lambda sen : [vocab.token_to_idx[token] for token in sen], X_tr))\n",
    "X_tr = pad_sequences(sequences = X_tr, maxlen = 30, padding = 'pre', value = 1.)\n",
    "\n",
    "X_val = list(map(lambda sen : [vocab.token_to_idx[token] for token in sen], X_val))\n",
    "X_val = pad_sequences(sequences = X_val, maxlen = 30, padding = 'pre', value = 1.)\n",
    "\n",
    "X_tst = list(map(lambda sen : [vocab.token_to_idx[token] for token in sen], X_tst))\n",
    "X_tst = pad_sequences(sequences = X_tst, maxlen = 30, padding = 'pre', value = 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define MorphConv class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorphConv:\n",
    "    def __init__(self, X, y, n_of_classes, embedding):\n",
    "        \n",
    "        with tf.variable_scope('input_layer'):\n",
    "            self.__X = X\n",
    "            self.__y = y\n",
    "            self.is_training = tf.placeholder(dtype = tf.bool)\n",
    "        \n",
    "        with tf.variable_scope('embedding_layer'):\n",
    "            static_embed = tf.get_variable(name = 'static', initializer = embedding,\n",
    "                                           trainable = False)\n",
    "            non_static_embed = tf.get_variable(name = 'non_static', initializer = embedding,\n",
    "                                               trainable = True)\n",
    "            static_batch = tf.nn.embedding_lookup(params = static_embed, ids = self.__X)\n",
    "            non_static_batch = tf.nn.embedding_lookup(params = non_static_embed, ids = self.__X)\n",
    "            \n",
    "        with tf.variable_scope('convoluion_layer'):\n",
    "            with tf.variable_scope('tri_gram'):\n",
    "                \n",
    "                tri_gram = keras.layers.Conv1D(filters = 100, kernel_size = 3,\n",
    "                                               activation = keras.activations.relu,\n",
    "                                               kernel_initializer = 'he_uniform', padding = 'valid')\n",
    "                static_3 = tri_gram(static_batch)\n",
    "                non_static_3 = tri_gram(non_static_batch)\n",
    "            \n",
    "            with tf.variable_scope('tetra_gram'):\n",
    "                tetra_gram = keras.layers.Conv1D(filters = 100, kernel_size = 4,\n",
    "                                                 activation = keras.activations.relu,\n",
    "                                                 kernel_initializer = 'he_uniform', padding = 'valid')\n",
    "                \n",
    "                static_4 = tetra_gram(static_batch)\n",
    "                non_static_4 = tetra_gram(non_static_batch)\n",
    "            \n",
    "            with tf.variable_scope('penta_gram'):\n",
    "                penta_gram = keras.layers.Conv1D(filters = 100, kernel_size = 5,\n",
    "                                                 activation = keras.activations.relu,\n",
    "                                                 kernel_initializer = 'he_uniform', padding = 'valid')\n",
    "                \n",
    "                static_5 = penta_gram(static_batch)\n",
    "                non_static_5 = penta_gram(non_static_batch)\n",
    "\n",
    "            fmap_3 = tf.reduce_max(static_3 + non_static_3, axis = 1)\n",
    "            fmap_4 = tf.reduce_max(static_4 + non_static_4, axis = 1)\n",
    "            fmap_5 = tf.reduce_max(static_5 + non_static_5, axis = 1)\n",
    "            \n",
    "        with tf.variable_scope('output_layer'):\n",
    "            flattened = tf.concat([fmap_3, fmap_4, fmap_5], axis = -1)\n",
    "            score = keras.layers.Dense(units = n_of_classes,\n",
    "                                       kernel_regularizer = keras.regularizers.l2(.7))(flattened)\n",
    "            \n",
    "            self.__score = keras.layers.Dropout(rate = .5)(score, training = self.is_training)\n",
    "\n",
    "        with tf.variable_scope('loss'):\n",
    "            ce_loss = tf.losses.sparse_softmax_cross_entropy(labels = self.__y, logits = self.__score)\n",
    "            reg_term = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "            self.total_loss = ce_loss + reg_term\n",
    "        \n",
    "        with tf.variable_scope('prediction'):\n",
    "            self.prediction = tf.argmax(self.__score, axis = -1)\n",
    "        \n",
    "    # predict instance method for small dataset\n",
    "    def predict(self, sess, x_data, is_training = False):\n",
    "        feed_prediction = {self.__X : x_data, self.is_training : is_training}\n",
    "        return sess.run(self.prediction, feed_dict = feed_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model of MorphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameter\n",
    "lr = 0.002\n",
    "epochs = 30\n",
    "batch_size = 5000\n",
    "total_step = int(X_tr.shape[0] / batch_size)\n",
    "print(total_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "tr_dataset = tf.data.Dataset.from_tensor_slices((X_tr, y_tr))\n",
    "tr_dataset = tr_dataset.shuffle(buffer_size = 1000000)\n",
    "tr_dataset = tr_dataset.batch(batch_size = batch_size)\n",
    "tr_iterator = tr_dataset.make_initializable_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size = batch_size)\n",
    "val_iterator = val_dataset.make_initializable_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anonymous iterator\n",
    "handle = tf.placeholder(dtype = tf.string)\n",
    "iterator = tf.data.Iterator.from_string_handle(string_handle = handle,\n",
    "                                               output_types = tr_iterator.output_types,\n",
    "                                               output_shapes = tr_iterator.output_shapes)\n",
    "x_data, y_data = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_conv = MorphConv(X = x_data, y = y_data, n_of_classes = 2,\n",
    "                       embedding = vocab.embedding.idx_to_vec.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training op\n",
    "opt = tf.train.AdamOptimizer(learning_rate = lr)\n",
    "training_op = opt.minimize(loss = morph_conv.total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(max_to_keep=30)\n",
    "save_dir = 'checkpoints/'\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "sess_config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "sess = tf.Session(config = sess_config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "tr_handle, val_handle = sess.run(fetches = [tr_iterator.string_handle(), val_iterator.string_handle()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4be400af291470aab3456c24ecaff48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   1, tr_loss : 1.279, val_loss : 0.619\n",
      "epoch :   2, tr_loss : 0.592, val_loss : 0.499\n",
      "epoch :   3, tr_loss : 0.519, val_loss : 0.457\n",
      "epoch :   4, tr_loss : 0.484, val_loss : 0.434\n",
      "epoch :   5, tr_loss : 0.463, val_loss : 0.420\n",
      "epoch :   6, tr_loss : 0.446, val_loss : 0.411\n",
      "epoch :   7, tr_loss : 0.434, val_loss : 0.406\n",
      "epoch :   8, tr_loss : 0.421, val_loss : 0.402\n",
      "epoch :   9, tr_loss : 0.411, val_loss : 0.399\n",
      "epoch :  10, tr_loss : 0.400, val_loss : 0.398\n",
      "epoch :  11, tr_loss : 0.392, val_loss : 0.398\n",
      "epoch :  12, tr_loss : 0.381, val_loss : 0.395\n",
      "epoch :  13, tr_loss : 0.374, val_loss : 0.396\n",
      "epoch :  14, tr_loss : 0.364, val_loss : 0.396\n",
      "epoch :  15, tr_loss : 0.356, val_loss : 0.397\n",
      "epoch :  16, tr_loss : 0.348, val_loss : 0.397\n",
      "epoch :  17, tr_loss : 0.340, val_loss : 0.398\n",
      "epoch :  18, tr_loss : 0.330, val_loss : 0.398\n",
      "epoch :  19, tr_loss : 0.324, val_loss : 0.401\n",
      "epoch :  20, tr_loss : 0.316, val_loss : 0.408\n",
      "epoch :  21, tr_loss : 0.308, val_loss : 0.408\n",
      "epoch :  22, tr_loss : 0.302, val_loss : 0.409\n",
      "epoch :  23, tr_loss : 0.296, val_loss : 0.415\n",
      "epoch :  24, tr_loss : 0.288, val_loss : 0.416\n",
      "epoch :  25, tr_loss : 0.281, val_loss : 0.419\n",
      "epoch :  26, tr_loss : 0.275, val_loss : 0.423\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tr_loss_hist = []\n",
    "val_loss_hist = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    avg_tr_loss = 0\n",
    "    avg_val_loss = 0\n",
    "    tr_step = 0\n",
    "    val_step = 0\n",
    "\n",
    "    # for mini-batch training\n",
    "    sess.run(tr_iterator.initializer)    \n",
    "    try:\n",
    "        \n",
    "        while True:\n",
    "            _, tr_loss = sess.run(fetches = [training_op, morph_conv.total_loss],\n",
    "                                             feed_dict = {handle : tr_handle, morph_conv.is_training : True})\n",
    "            avg_tr_loss += tr_loss\n",
    "            tr_step += 1\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "\n",
    "    # for validation\n",
    "    sess.run(val_iterator.initializer)\n",
    "    try:\n",
    "        while True:\n",
    "            val_loss = sess.run(fetches = morph_conv.total_loss,\n",
    "                                feed_dict = {handle : val_handle, morph_conv.is_training : False})\n",
    "            avg_val_loss += val_loss\n",
    "            val_step += 1\n",
    "    \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "\n",
    "    avg_tr_loss /= tr_step\n",
    "    avg_val_loss /= val_step\n",
    "    tr_loss_hist.append(avg_tr_loss)\n",
    "    val_loss_hist.append(avg_val_loss)\n",
    "    \n",
    "    saver.save(sess=sess, \n",
    "               save_path=save_dir+str(epoch).zfill(3)+'_'+str(int(avg_train_loss*1000)).zfill(4)+'_'+str(int(avg_val_loss*1000)).zfill(4)+'.ckpt')\n",
    "    \n",
    "    print('epoch : {:3}, tr_loss : {:.3f}, val_loss : {:.3f}'.format(epoch + 1, avg_tr_loss, avg_val_loss))\n",
    "    \n",
    "    threshold = 5\n",
    "    if epoch >= 5:\n",
    "        if all([prev_val_loss > val_loss for prev_val_loss \n",
    "                in val_loss_hist[epoch-threshold:epoch]]):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/017_398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/017_398\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess, save_dir+'017_398')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_dataset = tf.data.Dataset.from_tensor_slices((X_tst, y_tst))\n",
    "tst_dataset = tst_dataset.batch(batch_size = batch_size)\n",
    "tst_iterator = tst_dataset.make_initializable_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_handle = sess.run(tst_iterator.string_handle())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tst_hat = np.array([])\n",
    "\n",
    "sess.run(tst_iterator.initializer)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        y_tst_tmp = sess.run(morph_conv.prediction,\n",
    "                            feed_dict = {handle : tst_handle,\n",
    "                                         morph_conv.is_training : False})\n",
    "        y_tst_hat= np.append(y_tst_hat,y_tst_tmp)\n",
    "\n",
    "except tf.errors.OutOfRangeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc : 81.66%\n"
     ]
    }
   ],
   "source": [
    "print('test acc : {:.2%}'.format(np.mean(y_tst_hat == np.array(y_tst))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
