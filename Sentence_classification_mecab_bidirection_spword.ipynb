{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence classification by MorphConv\n",
    "Implementation of [Convolutional Neural Networks for Sentence Classification](https://arxiv.org/abs/1408.5882) to classify sentiment of movie review\n",
    "\n",
    "### Explanation of this notebook\n",
    "* Dataset : [Naver sentiment movie corpus v1.0](https://github.com/e9t/nsmc)\n",
    "    + train, validation : splitting `ratings_train.txt` (150k reviews) for train (120k reviews) and validation (30k reviews)\n",
    "    + test : `ratings_test.txt` (50k reviews)\n",
    "* Preprocessing\n",
    "    + Morphological analysis by Mecab wrapped by [konlpy](http://konlpy.org/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter \n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import (Input, Embedding, Conv1D, AveragePooling1D, \n",
    "                          concatenate, Bidirectional, GRU, Dense)\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "import re\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "ratings_train = pd.read_csv('data/ratings_train.txt', sep = '\\t')[['document', 'label']]\n",
    "ratings_test = pd.read_csv('data/ratings_test.txt', sep = '\\t')[['document', 'label']]\n",
    "\n",
    "# ratings, ratings_tst의 document column에 nan 값이 있으므로 이를 빈 문자열로 대체\n",
    "print(sum(ratings_train.document.isna()), sum(ratings_test.document.isna()))\n",
    "\n",
    "ratings_train.document[ratings_train.document.isna()] = ''\n",
    "ratings_test.document[ratings_test.document.isna()] = ''\n",
    "\n",
    "print(sum(ratings_train.document.isna()), sum(ratings_test.document.isna()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use mecab for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_morphs(text):\n",
    "    cleaned_text = re.sub('[^a-z|A-Z|가-힣|0-9|\\,|\\.|\\!|\\?]', ' ', text)\n",
    "    cleaned_text = re.sub('(\\!|\\?){2,}', '\\g<1>', cleaned_text)\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "    base_words = mecab.morphs(cleaned_text)\n",
    "    base_words = [word for word in base_words if '.' != word and ',' not in word]\n",
    "    base_words = [word if '..' not in word else '...' for word in base_words]\n",
    "    base_words = [word if word != '!' else '!!' for word in base_words]\n",
    "    base_words = [word if word != '?' else '??' for word in base_words]\n",
    "\n",
    "    \n",
    "    sp_text = re.sub('[^ㅎㅎ|^^|ㅡㅡ|\\-\\-|~|;|♥|♡|★|ㅠ|ㅜ|ㅋ|ㅎ|ㅇ|ㅂ|ㅅ|ㅊ|ㅈ|ㄷ|ㄴ|ㅌ]', \n",
    "                     ' ', text)\n",
    "    \n",
    "    sp_text = re.sub('(ㅡ.ㅡ|-.-)', ' ㅡㅡ ', sp_text)\n",
    "    sp_text = re.sub('(-|ㅡ){2,}', ' ㅡㅡ ', sp_text)\n",
    "    sp_text = re.sub('(ㅋ|ㅎ|ㅇ|ㅂ|ㅅ|ㅊ|ㅈ|ㄷ|ㄴ|ㅌ){2,}', ' \\g<1>\\g<1> ', sp_text)\n",
    "    sp_text = re.sub('(♥|♡)+', ' ♥♥ ', sp_text)\n",
    "    sp_text = re.sub('(★|;|~)+', ' \\g<1>\\g<1> ', sp_text)\n",
    "    sp_text = re.sub('\\^+', ' ^^ ', sp_text)\n",
    "    sp_text = re.sub('[ㅠ|ㅜ]+', ' ㅠㅠ ', sp_text)\n",
    "    sp_text = re.sub('\\s+', ' ', sp_text)\n",
    "    sp_text = sp_text.strip()\n",
    "    \n",
    "    sp_words = sp_text.split(' ')\n",
    "    sp_words = [word for word in sp_words if 'ㅡ' != word]\n",
    "    \n",
    "    result_text = base_words + sp_words if not '' in sp_words else base_words\n",
    "    if not result_text:\n",
    "        return ''\n",
    "    \n",
    "#     result_word = [word for word in result_word if len(word) > 1]\n",
    "    result_words = '+'.join(result_text)\n",
    "    return result_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make train morphs......\n",
      "Make test morphs......\n",
      "CPU times: user 31 s, sys: 151 ms, total: 31.2 s\n",
      "Wall time: 31.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train\n",
    "print('Make train morphs......')\n",
    "ratings_train['morphs'] = ratings_train['document'].apply(make_morphs)\n",
    "\n",
    "# test\n",
    "print('Make test morphs......')\n",
    "ratings_test['morphs'] = ratings_test['document'].apply(make_morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_train.to_csv('data/ratings_train_mecab_spword.txt', sep='\\t', index=False)\n",
    "ratings_test.to_csv('data/ratings_test_mecab_spword.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167 56\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv('data/ratings_train_mecab_spword.txt', sep = '\\t')[['morphs', 'label']]\n",
    "ratings_test = pd.read_csv('data/ratings_test_mecab_spword.txt', sep = '\\t')[['morphs', 'label']]\n",
    "\n",
    "# ratings, ratings_tst의 document column에 nan 값이 있으므로 이를 빈 문자열로 대체\n",
    "print(sum(ratings.morphs.isna()), sum(ratings_test.morphs.isna()))\n",
    "\n",
    "ratings.morphs[ratings.morphs.isna()] = ''\n",
    "ratings_test.morphs[ratings_test.morphs.isna()] = ''\n",
    "\n",
    "print(sum(ratings.morphs.isna()), sum(ratings_test.morphs.isna()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find best random seed trought rasidual and varience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find best seed......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c58f3664a0b4b9da4c8a190b2a77c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 0\n",
      "280028\n",
      "73093.95535086525 72788.64036922259\n",
      "seed: 4\n",
      "279283\n",
      "72659.20509965229 74530.59328873192\n",
      "seed: 8\n",
      "277420\n",
      "72949.85140907383 73359.04609988058\n",
      "seed: 108\n",
      "276936\n",
      "73050.30235850641 72953.05609298393\n",
      "seed: 128\n",
      "276021\n",
      "73141.69375567777 72588.56850242332\n",
      "seed: 267\n",
      "275940\n",
      "73197.65236750114 72370.5584639531\n",
      "seed: 1069\n",
      "275647\n",
      "73067.3642571775 72884.91745579352\n",
      "seed: 1395\n",
      "275052\n",
      "73194.207448039 72384.66283194325\n",
      "seed: 4843\n",
      "274889\n",
      "73004.69947935347 73136.23770602426\n",
      "seed: 5107\n",
      "274502\n",
      "73130.34417974179 72631.76975883021\n"
     ]
    }
   ],
   "source": [
    "# print('Find best seed......')\n",
    "\n",
    "# min_seed = 0\n",
    "# min_residual = 100000000\n",
    "# for i in tqdm(range(10000)):\n",
    "#     x_data = ratings.morphs.apply(split_word).tolist()\n",
    "#     y_data = ratings.label.tolist()\n",
    "\n",
    "#     x_train_word, x_val_word, y_train, y_val = train_test_split(x_data, y_data,\n",
    "#                                                                 test_size=0.2,\n",
    "#                                                                 random_state=i,\n",
    "#                                                                 stratify=y_data)\n",
    "#     # print(len(y_train), sum(y_train), len(y_val), sum(y_val))\n",
    "\n",
    "#     word_table = list(set([word for words in x_data for word in words]))\n",
    "#     word_table = {word:0 for word in word_table}\n",
    "\n",
    "#     train_counter = nlp.data.count_tokens(itertools.chain.from_iterable([c for c in x_train_word]))\n",
    "#     train_table = word_table.copy()\n",
    "#     train_table.update(train_counter)\n",
    "\n",
    "#     val_counter = nlp.data.count_tokens(itertools.chain.from_iterable([c for c in x_val_word]))\n",
    "#     val_table = word_table.copy()\n",
    "#     val_table.update(val_counter)\n",
    "\n",
    "#     train_cnt = np.array(list(train_table.values()))\n",
    "#     val_cnt = np.array(list(val_table.values())) * 4\n",
    "    \n",
    "#     residual = np.abs(train_cnt-val_cnt).sum()\n",
    "#     if residual < min_residual:\n",
    "#         min_residual = residual\n",
    "#         min_seed = i\n",
    "#         print('seed:', i)\n",
    "#         print(min_residual)\n",
    "#         print(np.var(train_cnt), np.var(val_cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_word(text):\n",
    "#     return text.split('+')\n",
    "    return [word for word in text.split('+')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make train, val data......\n"
     ]
    }
   ],
   "source": [
    "print('Make train, val data......')\n",
    "\n",
    "x_data = ratings.morphs.apply(split_word).tolist()\n",
    "y_data = ratings.label.tolist()\n",
    "\n",
    "x_train_word, x_val_word, y_train, y_val = train_test_split(x_data, y_data,\n",
    "                                                            test_size=0.2,\n",
    "                                                            random_state=349,\n",
    "                                                            stratify=y_data)\n",
    "\n",
    "y_train = np.asarray(y_train)\n",
    "y_val = np.asarray(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13.0, 150000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median([len(k) for k in keywords]), len(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_cnt = Counter([i for item in keywords for i in item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword_clip_dict = dict(keyword_clip)\n",
    "keyword_clip_dict = {key:value for key, value in keyword_cnt.items() if value >= 3}\n",
    "keyword_dict = dict(zip(keyword_clip_dict.keys(), range(len(keyword_clip_dict))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#공백과 미학습 단어 처리를 위한 사전 정보 추가\n",
    "keyword_dict['_PAD_'] = len(keyword_dict)\n",
    "keyword_dict['_UNK_'] = len(keyword_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#리뷰 시퀀스 단어수의 중앙값 +10를 max 리뷰 시퀀스로 정함... \n",
    "# max_seq = np.median([len(k) for k in keywords]) + 10\n",
    "max_seq = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_and_padding(corp_list, dic, max_seq=50):\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    coding_seq = [ [dic.get(j, dic['_UNK_']) for j in i]  for i in corp_list ]\n",
    "    #일반적으로 리뷰는 마지막 부분에 많은 정보를 포함할 가능성이 많아 패딩은 앞에 준다. \n",
    "    return(pad_sequences(coding_seq, maxlen=max_seq, padding='pre', truncating='pre',value=dic['_PAD_']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = encoding_and_padding(x_train_word, keyword_dict, max_seq=int(max_seq))\n",
    "x_val = encoding_and_padding(x_val_word, keyword_dict, max_seq=int(max_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120000, 20), (120000,), (30000, 20), (30000,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define MorphConv class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 20, 50)       1108400     input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 20, 32)       1632        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 20, 16)       1616        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 20, 8)        1208        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_10 (AveragePo (None, 10, 32)       0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_11 (AveragePo (None, 10, 16)       0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_12 (AveragePo (None, 10, 8)        0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 10, 56)       0           average_pooling1d_10[0][0]       \n",
      "                                                                 average_pooling1d_11[0][0]       \n",
      "                                                                 average_pooling1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 20)           4020        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            21          bidirectional_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,116,897\n",
      "Trainable params: 1,116,897\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(x_train.shape[1],), name='input')\n",
    "embeddings_out = Embedding(input_dim=len(keyword_dict), \n",
    "                           output_dim=50,\n",
    "                           name='embedding')(inputs)\n",
    "\n",
    "conv0 = Conv1D(32, 1, padding='same')(embeddings_out)\n",
    "conv1 = Conv1D(16, 2, padding='same')(embeddings_out)\n",
    "conv2 = Conv1D(8, 3, padding='same')(embeddings_out)\n",
    "\n",
    "pool0 = AveragePooling1D()(conv0)\n",
    "pool1 = AveragePooling1D()(conv1)\n",
    "pool2 = AveragePooling1D()(conv2)\n",
    "\n",
    "concat_layer = concatenate([pool0, pool1, pool2],axis=2)\n",
    "\n",
    "bidir = Bidirectional(GRU(10, recurrent_dropout=0.2, dropout=0.2))(concat_layer)\n",
    "\n",
    "out = Dense(1,activation='sigmoid')(bidir)\n",
    "\n",
    "model = Model(inputs=[inputs,], outputs=out)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameter\n",
    "lr = 0.0003\n",
    "epochs = 30 # 30\n",
    "batch_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(lr=lr),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', \n",
    "#               optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=1e-6, nesterov=True),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'checkpoint/'\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "model_filename = model_path+'{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_acc\", verbose=1, save_best_only=True)\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/30\n",
      "120000/120000 [==============================] - 4s 37us/step - loss: 0.6919 - acc: 0.5466 - val_loss: 0.6901 - val_acc: 0.6285\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.62853, saving model to checkpoint/01-0.6901.hdf5\n",
      "Epoch 2/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.6881 - acc: 0.6450 - val_loss: 0.6856 - val_acc: 0.6962\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.62853 to 0.69620, saving model to checkpoint/02-0.6856.hdf5\n",
      "Epoch 3/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.6821 - acc: 0.7065 - val_loss: 0.6780 - val_acc: 0.7234\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.69620 to 0.72343, saving model to checkpoint/03-0.6780.hdf5\n",
      "Epoch 4/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.6721 - acc: 0.7321 - val_loss: 0.6657 - val_acc: 0.7394\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.72343 to 0.73937, saving model to checkpoint/04-0.6657.hdf5\n",
      "Epoch 5/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.6566 - acc: 0.7494 - val_loss: 0.6470 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.73937 to 0.75003, saving model to checkpoint/05-0.6470.hdf5\n",
      "Epoch 6/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.6335 - acc: 0.7586 - val_loss: 0.6207 - val_acc: 0.7585\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.75003 to 0.75847, saving model to checkpoint/06-0.6207.hdf5\n",
      "Epoch 7/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.6032 - acc: 0.7711 - val_loss: 0.5878 - val_acc: 0.7690\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.75847 to 0.76900, saving model to checkpoint/07-0.5878.hdf5\n",
      "Epoch 8/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.5673 - acc: 0.7799 - val_loss: 0.5516 - val_acc: 0.7789\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.76900 to 0.77887, saving model to checkpoint/08-0.5516.hdf5\n",
      "Epoch 9/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.5300 - acc: 0.7902 - val_loss: 0.5167 - val_acc: 0.7888\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.77887 to 0.78880, saving model to checkpoint/09-0.5167.hdf5\n",
      "Epoch 10/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.4949 - acc: 0.8006 - val_loss: 0.4856 - val_acc: 0.7986\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.78880 to 0.79857, saving model to checkpoint/10-0.4856.hdf5\n",
      "Epoch 11/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.4636 - acc: 0.8117 - val_loss: 0.4593 - val_acc: 0.8084\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.79857 to 0.80840, saving model to checkpoint/11-0.4593.hdf5\n",
      "Epoch 12/30\n",
      "120000/120000 [==============================] - 1s 7us/step - loss: 0.4364 - acc: 0.8231 - val_loss: 0.4372 - val_acc: 0.8167\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.80840 to 0.81670, saving model to checkpoint/12-0.4372.hdf5\n",
      "Epoch 13/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.4127 - acc: 0.8329 - val_loss: 0.4190 - val_acc: 0.8248\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.81670 to 0.82477, saving model to checkpoint/13-0.4190.hdf5\n",
      "Epoch 14/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.3921 - acc: 0.8417 - val_loss: 0.4038 - val_acc: 0.8300\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.82477 to 0.83000, saving model to checkpoint/14-0.4038.hdf5\n",
      "Epoch 15/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.3745 - acc: 0.8499 - val_loss: 0.3916 - val_acc: 0.8356\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.83000 to 0.83557, saving model to checkpoint/15-0.3916.hdf5\n",
      "Epoch 16/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.3593 - acc: 0.8552 - val_loss: 0.3820 - val_acc: 0.8382\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.83557 to 0.83817, saving model to checkpoint/16-0.3820.hdf5\n",
      "Epoch 17/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.3458 - acc: 0.8610 - val_loss: 0.3745 - val_acc: 0.8410\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.83817 to 0.84103, saving model to checkpoint/17-0.3745.hdf5\n",
      "Epoch 18/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.3347 - acc: 0.8655 - val_loss: 0.3691 - val_acc: 0.8434\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.84103 to 0.84343, saving model to checkpoint/18-0.3691.hdf5\n",
      "Epoch 19/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.3254 - acc: 0.8695 - val_loss: 0.3651 - val_acc: 0.8446\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.84343 to 0.84463, saving model to checkpoint/19-0.3651.hdf5\n",
      "Epoch 20/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.3173 - acc: 0.8733 - val_loss: 0.3628 - val_acc: 0.8450\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.84463 to 0.84497, saving model to checkpoint/20-0.3628.hdf5\n",
      "Epoch 21/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.3100 - acc: 0.8754 - val_loss: 0.3610 - val_acc: 0.8449\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.84497\n",
      "Epoch 22/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.3040 - acc: 0.8783 - val_loss: 0.3604 - val_acc: 0.8451\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.84497 to 0.84513, saving model to checkpoint/22-0.3604.hdf5\n",
      "Epoch 23/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.2985 - acc: 0.8810 - val_loss: 0.3607 - val_acc: 0.8447\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.84513\n",
      "Epoch 24/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.2941 - acc: 0.8825 - val_loss: 0.3611 - val_acc: 0.8446\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.84513\n",
      "Epoch 25/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.2905 - acc: 0.8848 - val_loss: 0.3618 - val_acc: 0.8447\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.84513\n",
      "Epoch 26/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.2861 - acc: 0.8861 - val_loss: 0.3629 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.84513\n",
      "Epoch 27/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.2828 - acc: 0.8880 - val_loss: 0.3643 - val_acc: 0.8440\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.84513\n",
      "Epoch 28/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.2803 - acc: 0.8901 - val_loss: 0.3662 - val_acc: 0.8439\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.84513\n",
      "Epoch 29/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.2773 - acc: 0.8911 - val_loss: 0.3674 - val_acc: 0.8439\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.84513\n",
      "Epoch 30/30\n",
      "120000/120000 [==============================] - 1s 6us/step - loss: 0.2739 - acc: 0.8926 - val_loss: 0.3694 - val_acc: 0.8435\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.84513\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit( x=x_train, y=y_train, \n",
    "                  batch_size=batch_size, epochs=epochs, \n",
    "                  validation_data=[x_val, y_val],\n",
    "                  shuffle=True, callbacks = [checkpointer] )\n",
    "#                  shuffle=True, callbacks = [checkpointer, early_stopping] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd8VFX6x/HPMymT3hNKAiRA6CAgUoRV7IACIioq+FPXuopl190VXXXVxbauuvbOrroqKgiigtiwUkMRQu+QAOm9J3N+f9whBAwQymQyM8/79ZrXzNx7Z/LcDMw395x7zxFjDEoppRSAzd0FKKWUajk0FJRSStXTUFBKKVVPQ0EppVQ9DQWllFL1NBSUUkrV01BQqolE5L8iMrWJ2+4QkXNP9H2Uam4aCkoppeppKCillKqnoaC8irPZ5i8islpEykTkLRFpJSLzRKRERL4RkegG248RkbUiUigi34tI9wbr+onICufrPgSCDvlZF4nIKudrF4pIn+Os+UYR2SIi+SIyR0TaOpeLiDwrItkiUiwia0Skl3PdKBFZ56wtU0T+fFy/MKUOoaGgvNF44DygCzAamAfcB8Rj/Zu/A0BEugAfAHc5180FPhORQBEJBGYD7wIxwMfO98X52n7ANOBmIBZ4DZgjIvZjKVREzgYeBy4H2gA7genO1ecDZzj3I9K5TZ5z3VvAzcaYcKAX8N2x/FylDkdDQXmjF4wxWcaYTOAnYIkxZqUxphKYBfRzbjcB+MIY87Uxpgb4FxAMnA4MBgKAfxtjaowxM4BlDX7GTcBrxpglxpg6Y8zbQJXzdcdiIjDNGLPCGFMF3AsMEZFkoAYIB7oBYoxZb4zZ63xdDdBDRCKMMQXGmBXH+HOVapSGgvJGWQ0eVzTyPMz5uC3WX+YAGGMcwG4g0bku0xw8YuTOBo87AHc7m44KRaQQaOd83bE4tIZSrKOBRGPMd8CLwEtAtoi8LiIRzk3HA6OAnSLyg4gMOcafq1SjNBSUL9uD9eUOWG34WF/smcBeING5bL/2DR7vBh41xkQ1uIUYYz44wRpCsZqjMgGMMc8bY04FemA1I/3FuXyZMWYskIDVzPXRMf5cpRqloaB82UfAhSJyjogEAHdjNQEtBBYBtcAdIhIgIpcAAxu89g3gFhEZ5OwQDhWRC0Uk/Bhr+AC4TkT6OvsjHsNq7tohIqc53z8AKAMqAYezz2OiiEQ6m72KAccJ/B6UqqehoHyWMWYjMAl4AcjF6pQebYypNsZUA5cA1wL5WP0PnzR4bRpwI1bzTgGwxbntsdbwDfAAMBPr6KQTcIVzdQRW+BRgNTHlAU85110N7BCRYuAWrL4JpU6Y6CQ7Siml9tMjBaWUUvU0FJRSStXTUFBKKVVPQ0EppVQ9f3cXcKzi4uJMcnKyu8tQSimPsnz58lxjTPzRtvO4UEhOTiYtLc3dZSillEcRkZ1H30qbj5RSSjXg0lAQkREistE5LPCURtY/6xx6eJWIbHKOH6OUUspNXNZ8JCJ+WAN5nQdkAMtEZI4xZt3+bYwxf2yw/e0cGL1SKaWUG7iyT2EgsMUYsw1ARKYDY4F1h9n+SuDvx/ODampqyMjIoLKy8rgK9SRBQUEkJSUREBDg7lKUUl7IlaGQiDWS5H4ZwKDGNhSRDkAKh5koRERuwhq/nvbt2/9mfUZGBuHh4SQnJ3PwoJbexRhDXl4eGRkZpKSkuLscpZQXaikdzVcAM4wxdY2tNMa8bowZYIwZEB//2zOqKisriY2N9epAABARYmNjfeKISCnlHq4MhUyssen3S3Iua8wVWEMIHzdvD4T9fGU/lVLu4cpQWAakikiKc77bK4A5h24kIt2AaKzx612mrKqWrOJKiipqqKqpQ0eHVUqp33JZKBhjaoHJwHxgPfCRMWatiDwiImMabHoFMN24+Fu6trwQe8kuyvL3kJGVw/o9hWzOKmFXfjnZxZUUV9RQVXt8YVFYWMjLL798zK8bNWoUhYV6Fq5SquVw6RXNxpi5wNxDlj14yPOHXFnDfpGBgqmqJspRBgIGqHEEUlFpp9QEUmzsVBIIYsPubyPU7k+Y3Z9Quz9+tiM32ewPhVtvvfWg5bW1tfj7H/5XPHfu3MOuU0opd/C4YS6OW2gsEhoLdTVQU47UlBNYXU5gTTmRjhJnUAg1EkilsVNYFsSu0hCM2AgJ9CPc7k9YkD/BAX6/adefMmUKW7dupW/fvgQEBBAUFER0dDQbNmxg06ZNXHzxxezevZvKykruvPNObrrpJuDAkB2lpaWMHDmSYcOGsXDhQhITE/n0008JDg52x29KKeXDvC4UHv5sLev2FB/bi4wBUwfGAQ7nPVYzkkP8SIkL5+phndlXLPjZhDC7P+FB/oTZAwj0t/HEE0+Qnp7OqlWr+P7777nwwgtJT0+vP2102rRpxMTEUFFRwWmnncb48eOJjY09qITNmzfzwQcf8MYbb3D55Zczc+ZMJk2adDJ+JUop1WReFwrHRQTE+avwcy4zdVBXi81RSyhl9PLbTXVAOMWEkVsNRRU1QAVBAX6UlVUd9HYDBw486DqC559/nlmzZgGwe/duNm/e/JtQSElJoW/fvgCceuqp7NixwxV7qpRSR+R1ofD30T1P7hsaB1SVQkUB9soi4k0hceJHXUgkpbZwcqv82FdcRVWtg31FldTWOQgNDa1/+ffff88333zDokWLCAkJYfjw4Y1eZ2C32+sf+/n5UVFRcXL3QymlmsDrQuGkExsERVg3hwOqipGKQvyrCoky+UTaAghpHUh5WSnZJZXsyi+nsqaOypo6ggL8KCoqIjo6mpCQEDZs2MDixYvdvUdKKXVYGgrHwmaD4Cjr5qizAqI0m7b2cs48rQ9Xnj+EgKAQImPi2ZRVQnhQAEOHn8Orr75K9+7d6dq1K4MHD3b3Xiil1GGJp13ENWDAAHPoJDvr16+ne/fu7inIGKgshOI9UFcN9nDqwtqSV2Ujt6ya2joHQQF+xIXZiQoJwHYSrkh26/4qpTySiCw3xgw42nYtZewjzyUCwdGQ0B0iEqG6HL+8jSQ4sugWH0RSdAgAGQXlbMkupbKm0eGdlFKqRdDmo5NFbBCWAMExUJoFZTnYyguJCUsgOj6B4ioHmQUVbM4upXVEEHFhgTqOkVKqxdFQONn8/CEyEULjrCal0n1IeS6R4W0ISYgms7CSvUUVlFTW0C46hAB/PVhTSrUc+o3kKv52iEmBuC7W46LdBBRuo0O0ncSoYMqr69iUXUJRebW7K1VKqXoaCq4WGAqxqRDVHqrLkNxNxAYZUhPCsPvb2Jlfzu78cuocDndXqpRSGgrNQgRCYiG2MzhqIWcTdkc5HePDSIgIorC8ms1ZpZRV1bq7UqWUj9NQaE72MIjvSljnwZC3lX3b1jL595PoGB8GAttyStlXVIHDGIYPH86hp94qpZSraUdzc/O3W2cqBYbRlhJmTHsOAv1ITQhnb2EF2SVVlFbV4WGXjyilvISGwkkwZcoU2rVrx2233QbAQw89hL+/PwsWLKCgoICamhqmTp3K2LFjD7wotiM71izmorPPJH3hV1TbE/jzrTewctUqkpI7U1hSqv0MSqlm532hMG8K7Ftzct+zdW8Y+cRhV0+YMIG77rqrPhQ++ugj5s+fzx133EFERAS5ubkMHjyYMWPGHLg2QWwQ3gZs/lBZxCsvvk5IcBAbN2xg4dLlnHH6IPYUVlLnMEed5EcppU4W7wsFN+jXrx/Z2dns2bOHnJwcoqOjad26NX/84x/58ccfsdlsZGZmkpWVRevWrQ+8UMQKhZiO/LhwCXfcMAmqyzl94Kn07NWbqhoHO/PKSI4NxabBoJRqBt4XCkf4i96VLrvsMmbMmMG+ffuYMGEC7733Hjk5OSxfvpyAgACSk5MbHTIbgKBICAyzQiJvM0R1wM8mJETaKa2qZWd+OR1iQ07KuElKKXUkevbRSTJhwgSmT5/OjBkzuOyyyygqKiIhIYGAgAAWLFjAzp07j/j6M4afxftzfwb/INIXfc3q1auJCAogKTqYksoaduWV49DeZ6WUi3nfkYKb9OzZk5KSEhITE2nTpg0TJ05k9OjR9O7dmwEDBtCtW7cjvv4Pf/gD1113Hd3PuJjuHZM4tU93qK0kJtSOw8Cewgoy8itoF6PzNiulXEdD4SRas+ZAB3dcXByLFi1qdLvS0lIAkpOTSU9PByA4OJjp06dbG9RWQ+4mqzmproa4MDvGGPYWVSIF6OmqSimX0eajlsg/0Bo3qa4W8reBw0F8eBCtIoIoKK+mqKIaT5sHQynlGTQUWqrAUIjuADXlULgLjCEh3E58uJ3SqjqmfrFeg0EpddJ5TSh45RdkcJR1LUNlgTUEtwitwu2E2f156+ftPP3VJndXqJTyMl4RCkFBQeTl5XlnMIS1sibuKdmHKcsjPz+f1jHhXDmwHS8u2MK0n7e7u0KllBfxio7mpKQkMjIyyMnJcXcprmEMlBXDzjSCIhNISu3Fox38yS2t5vF56xmQHE2fpCh3V6mU8gLiaX9dDxgwwPjk6KFlefDm2VBdBjd+B1HtKSyvZtRzPxHgb+Pz24cRHhTg7iqVUi2UiCw3xgw42nZe0XzkE0Jj4aqPrNNV358AlcVEhQTy3JX92J1fzgOz072z+Uwp1aw0FDxJfFe4/L+QsxFmXg+OOk5LjuGuc7swe9UeZq7IdHeFSikPp6HgaTqdDaOegs1fwVf3A3DbWZ0Z3DGGBz9NZ1tOqZsLVEp5Mg0FT3Ta9TD4Vlj8Mqx4Fz+b8O8J/bD725j8/kqqauvcXaFSykNpKHiq86dCyhnw5RQo2EnryCCeuvQU1u0t5vG5G9xdnVLKQ2koeCqbH4x9CRD49DZwODi3RyuuPT2Z/y7cwTfrstxdoVLKA2koeLKo9nDBo7DjJ0h7C4B7R3WjR5sI/jLjV/YVHWb+BqWUOgwNBU/X//+g87nw9YOQtxW7vx8vXNWPqloHd05fSZ1DT1NVSjWdhoKnE4HRz4MtoL4ZqVN8GI+M7cWS7fm8tGCLuytUSnkQDQVvEJloTUO6axEseRWA8f0TubhvW/79zSaWbs93c4FKKU+hoeAtTrkSuoyAbx+G3M2ICFPH9aZdTAh3TV9JYXm1uytUSnkAl4aCiIwQkY0iskVEphxmm8tFZJ2IrBWR911Zj1cTgdHPgX8QzP4DOOoIs/vzwpX9yCmt4q8zVuswGEqpo3JZKIiIH/ASMBLoAVwpIj0O2SYVuBcYaozpCdzlqnp8QnhrGPUvyFgGC18AoE9SFH8+vytfrcti7pp9bi5QKdXSufJIYSCwxRizzRhTDUwHxh6yzY3AS8aYAgBjTLYL6/ENvS+F7qNhwaOQbV3Edv2wFHq2jeDhz9ZSUlnj5gKVUi2ZK0MhEdjd4HmGc1lDXYAuIvKLiCwWkRGNvZGI3CQiaSKS5rVzJpwsInDhs2APh9m3QF0t/n42Hh3Xm5zSKp2tTSl1RO7uaPYHUoHhwJXAGyLym9lijDGvG2MGGGMGxMfHN3OJHigsHi58GvashF+eBaBvuyiuHtyBdxbtYHVGoXvrU0q1WK4MhUygXYPnSc5lDWUAc4wxNcaY7cAmrJBQJ6rnOOh5CXz/JOxLB+DPF3QlNszO32al60VtSqlGuTIUlgGpIpIiIoHAFcCcQ7aZjXWUgIjEYTUnbXNhTb5l1L8gOMpqRqqtJiIogAcu6sGazCLeXbTD3dUppVogl4WCMaYWmAzMB9YDHxlj1orIIyIyxrnZfCBPRNYBC4C/GGPyXFWTzwmNtU5T3bcGfnoagNF92vC71Dj+9dUmsop1bCSl1MF0jmZf8MlNkD4Tbv4JWvVgR24Z5//7R87r0YqXrurv7uqUUs1A52hWB1zwuHU20hd/AoeD5LhQJp/VmS9W7+X7jXoWsFLqAA0FXxAaC+f9wxob6VfrovGbz+xIx/hQHvg0ncoanalNKWXRUPAVfSdCu8Hw1QNQno/d34+pF/did34FL36nI6kqpSwaCr7CZoOLnoGqYmvuBeD0TnFc0i+R137cypbsEjcXqJRqCTQUfEmrnjD4Vlj5LuxaDMB9F3YnOMCP+2al64B5SikNBZ9z5j0QkQSf/xHqaogLszNlZHeWbs9n5opDry1USvkaDQVfYw+DUf+E7HWw+BUArjitHf3bR/HY3PUUlOm8C0r5Mg0FX9TtQugyEr5/AooysNmER8f1pqiihifmbXB3dUopN9JQ8FWj/gkYmHcPAN3bRHD9sBQ+TNvNsh06fadSvkpDwVdFtYcz/wobPoeNXwJw5zmptI0M4oHZ6dTWOdxcoFLKHTQUfNng2yC+G8z7C1SXE2r35/6LerBhXwn/W7zT3dUppdxAQ8GX+QfChc9A4S748SkARvZqzbDOcTz99SZyS6vcXKBSqrlpKPi65KHW1c4Ln4fsDYgID43pQUV1HU9qp7NSPkdDQcF5j0BgGHxxNxhD54Rwrh+WwsfLM1ixq8Dd1SmlmpGGgoLQOCsYdv4Mv04H4PZzUmkVYefBT3WWNqV8iYaCsvS7GpIGwld/g/J8wuz+3DeqO+mZxUxftsvd1SmlmomGgrLYbHDRs1BRCN/8HYAxp7RlUEoMT83fqFc6K+UjNBTUAa17wemTYcU7sONnRIRHxvaipLKWp77a6O7qlFLNQENBHezMKRCdDJ/dCTWVdG0dzjVDkvlg6S5WZxS6uzqllItpKKiDBYZYzUh5W+CnpwG467xUYkPtPPjpWhza6ayUV9NQUL/V6WzocwX8/CxkryciKIB7R3Zj1e5CZizPcHd1SikX0lBQjbvgMbCHw5w7wOHgkv6JDOgQzZNfbqCovMbd1SmlXERDQTUuNBZGPA4ZSyHtLUSEh8f2pKC8mme+1k5npbyVhoI6vD4ToONZ8M3DUJRJz7aRTBrcgXcX72TdnmJ3V6eUcgENBXV4Ilans6MW5v0VgLvP60pUSCB/n6NzOivljTQU1JHFpMDwKda8C+vmEBkSwD0jurJsRwGzV+mczkp5Gw0FdXRDJkPr3jD3L1BZxGWntuOUdlE8+sUGiiq001kpb6KhoI7Ozx9GPw9l2fDNQ9aczhf3Ir+sin9+qcNrK+VNNBRU0yT2h0F/gLRpsHMRvRIj+f3QFN5bsos0ndNZKa+hoaCa7qz7ILK9NQRGbRV/PK8LiVHB3PvJGqprdU5npbyBhoJqOnsYXPg05G6En/9NqN2fqRf3YnN2Ka/9sNXd1SmlTgINBXVsupwPvcbDT/+CnI2c1S2BC/u04YUFW9iWU+ru6pRSJ0hDQR27EU9AQIjVjOSo4++je2D3t3HfrDV67YJSHk5DQR27sARrbKRdi2Dh8ySEB3HvyO4s3pbPxzpgnlIeTUNBHZ++V0H3MfDdVNizkitOa8dpydE8Nnc9uaVV7q5OKXWcNBTU8RGB0c9BWCuYeQO22nIev6Q3ZVW1TP18nburU0odJw0FdfxCYmDcq5C3Fb6cQueEcP4wvDOzV+3hx0057q5OKXUcNBTUiUk5A4beac3rvG4Otw7vRMf4UP42ew0V1XXurk4pdYxcGgoiMkJENorIFhGZ0sj6a0UkR0RWOW83uLIe5SJn/Q3a9IXP7iCoIovHxvVmd34F//52k7srU0odI5eFgoj4AS8BI4EewJUi0qORTT80xvR13t50VT3KhfwDYfxbUFsFs25mcHI0Ewa0482ftuu8C0p5GFceKQwEthhjthljqoHpwFgX/jzlTnGdresXtv8IC5/n3lHdiA4J4N5PVlPn0GsXlPIUrgyFRGB3g+cZzmWHGi8iq0Vkhoi0a+yNROQmEUkTkbScHO3AbLH6/x90Hw3fTSWqcC0PXNSDXzOKeHfRDndXppRqInd3NH8GJBtj+gBfA283tpEx5nVjzABjzID4+PhmLVAdAxFriO3QeJh5A2O6R3JGl3iemr+RPYUV7q5OKdUETQoFEblTRCLE8paIrBCR84/yskyg4V/+Sc5l9YwxecaY/Vc6vQmc2tTCVQsVEgOXvAZ5W5H59/Hoxb1wGLhn5moc2oykVIvX1COF3xtjioHzgWjgauCJo7xmGZAqIikiEghcAcxpuIGItGnwdAywvon1qJYs5QwYegeseJt2Wd9y/0Xd+WlzLv9ZuMPdlSmljqKpoSDO+1HAu8aYtQ2WNcoYUwtMBuZjfdl/ZIxZKyKPiMgY52Z3iMhaEfkVuAO49lh3QLVQZ91vnaY653au6ubPud1b8eS8Dazfq2cjKdWSSVNGtRSR/2B1EqcApwB+wPfGmGZv7hkwYIBJS0tr7h+rjkfuZnjtDEg6jbxLPmTE878QHRLAnMnDCArwc3d1SvkUEVlujBlwtO2aeqRwPTAFOM0YUw4EANedQH3KF8SlwojHYfsPxK54kX9ddgqbskp5Yp7O66xUS9XUUBgCbDTGFIrIJOB+oMh1ZSmv0f8a6H0ZLJjKmbULuW5oMv9duIMFG7LdXZlSqhFNDYVXgHIROQW4G9gKvOOyqpT3EIExL0LSQPjkZqb0qaBrq3D+MuNXHWJbqRaoqaFQa6zOh7HAi8aYl4Bw15WlvEpAEFzxHoTGY/94Ii+NbkVxZS33zFitM7Up1cI0NRRKRORerFNRvxARG1a/glJNE5YAV30I1WV0/uYGHji/A99uyOZ/S3a5uzKlVANNDYUJQBXW9Qr7sC5Ee8plVSnv1KoHXDoNstKZtGcqw1Njmfr5OrZkl7i7MqWUU5NCwRkE7wGRInIRUGmM0T4Fdey6nA8XPI5s+IKXWn9GqN2fOz5YRVWtzr2gVEvQ1GEuLgeWApcBlwNLRORSVxamvNigm2HA9YQue5F3+m9h3d5inv5K515QqiXwb+J2f8O6RiEbQETigW+AGa4qTHkxERj5JORvpdfyB/hbz2d59Ec4s0s8QzvHubs6pXxaU/sUbPsDwSnvGF6r1G/5BcBlb0NMCjfseYBhscXc/dGvFJRVu7sypXxaU7/YvxSR+c7pM68FvgDmuq4s5ROCo+CqDxGEt/yfoqYsj3s/WaOnqSrlRk3taP4L8DrQx3l73RhzjysLUz4ipiNM+B/2kl18mvAm36zN4NUftrm7KqV8VlP7FDDGzARmurAW5auSh8Lo50j69Fb+2yqBq+f70a11OGd1S3B3ZUr5nCOGgoiUAI0dywtgjDERLqlK+Z5+EyFvC8N+foZnImzc8YE/s24bRueEMHdXppRPOWIoGGN0KAvVfM55EGoqGLfkFcpttdz0tp1Zk4cRGawXzyvVXJrcfKSUy4lYQ22LMHHxy9QW13HH+yFMu24gfrYjzumklDpJ9LRS1bKIwAWPweDbuMbvS4Zvf5p/ztNZWpVqLhoKquURgQsehSGTuc5/Pm0XPcisFbvdXZVSPkFDQbVMInD+VOqGTOYa/68pn/0nVu8ucHdVSnk9DQXVcongd/5UKk6bzETbV2z+z81kF5W7uyqlvJqGgmrZRAgeNZXcU25lvGM+K1/5PVU1Ne6uSimvpaGgWj4R4i5+jK1db+SCynmsfPk6jEOH2lbKFTQUlGcQodMVT7Ek8VoGF3zGpreuB4fD3VUp5XU0FJTnEOG03z/LF1ET6Zo5i+z/ToRq7WNQ6mTSUFAexeZn48xbnuPNoOuI2zmP8tfOg6IMd5ellNfQUFAeJywogDG3PcF9QffhyNtK7avDYfdSd5ellFfQUFAeKSE8iNtunswNAU+wt8IP858LYeV77i5LKY+noaA8VruYEKbeOJ5J8hhpdINPb4Uv74O6WneXppTH0lBQHq1zQjgvXn8uN9ZNYVbgRbD4JXj/cqgodHdpSnkkDQXl8XonRfLqNYOZUj6JF0Jvx2z/Ed48B3I3u7s0pTyOhoLyCoM7xvLKpP48V3A6D0U/jqkogDfOgS3fuLs0pTyKhoLyGmd3a8XTl5/CO3va8tfo5zCRSfDeZfDL83qhm1JNpKGgvMrYvolMvbgXH2+18ZfIpzBdL4SvH4D/jdPrGZRqAg0F5XUmDurAPSO6MWNNIfcH/hVz4bPWdQwvnw6/TgfT2LTjSinQUFBe6g/DO3HLmZ14b+lunsw9HXPLz5DQDWbdDB9dDWW57i5RqRZJQ0F5rXtGdGXioPa8+sNW/rGwCsc1c+Hch2HTfHh5MGyY6+4SlWpx/N1dgFKuIiL8Y2wvAv1tTPtlO8WVNTxxyR34p54Hn9wM06+EvpNgxOMQFOHucpVqEfRIQXk1m0148KIe/Om8LsxYnsGt762gMqYb3Pgd/O5u+PV9eGUobP/J3aUq1SK4NBREZISIbBSRLSIy5QjbjRcRIyIDXFmP8k0iwh3npPLQ6B58tS6L6/6zjNI6G5zzIPz+K/ALgLcvgi/v1aG4lc9zWSiIiB/wEjAS6AFcKSI9GtkuHLgTWOKqWpQCuHZoCs9OOIWlO/KZ+MZiCsqqod1pcMtPMPAmWPwyvHCqNbCezuymfJQrjxQGAluMMduMMdXAdGBsI9v9A3gSqHRhLUoBMK5fEq9NOpX1+0q4/LVF7CuqhMBQGPUUXDcPItpYA+u9dgZs+dbd5SrV7FwZConA7gbPM5zL6olIf6CdMeaLI72RiNwkImkikpaTk3PyK1U+5dwerXj7uoHsLapk/CsL2ZFbZq3ocDrc8C1cOg2qSuB/l8C742DfGvcWrFQzcltHs4jYgGeAu4+2rTHmdWPMAGPMgPj4eNcXp7zekE6xvH/jIMqra7n01UWs21NsrRCBXuNh8jK44HHYsxJe/R3M+gMUZbq3aKWagStDIRNo1+B5knPZfuFAL+B7EdkBDAbmaGezai59kqL4+JYhBPgJV7y+iOU78w+s9LfDkFvhjpVw+u2QPhNe6A/fPAyVRe4rWikXc2UoLANSRSRFRAKBK4A5+1caY4qMMXHGmGRjTDKwGBhjjElzYU1KHaRzQjgf3zKE2DA7E99cwtfrsg7eIDgazv8H3J4G3cfAz8/A8/1g0ctQVeqeopVyIZeFgjGmFpgMzAfWAx8ZY9aKyCMiMsZVP1epY5UUHcLHtwwhNSGcG99J45mvN+FwHDI+UlR7GP8G3PQ9JPSA+ffCM92tmd7yt7ujbKVcQoyHDQ42YMAAk5amBxP8ib9NAAASr0lEQVTq5KusqeP+2enMWJ7BWV3j+feEfkSGBDS+8e5lsOQVWPepdfpq11Ew+BZI/p3VL6FUCyMiy40xR22e11BQqgFjDO8t2cXDn62lTWQwr119Kt3bHGEIjOI9sOxNSPsPVORDQk8YdDP0uRwCgpuvcKWOQkNBqROwfGcBt763nKKKGp4c34exfROP/IKaClgzA5a8ClnpEBwDp14Lp90AkUd5rVLNQENBqROUXVLJ5PdXsnR7PtcNTea+Ud0J8DtKN5wxsONnKxw2zgUEOp8DPcdZTUzBUc1Su1KH0lBQ6iSoqXPw+NwNTPtlOwNTYnjxqn4khAc17cUFOyBtGqR/AkW7wRbQICBGQlCkS2tXqiENBaVOok9XZXLPzNVEBgfw8sRTObVDdNNfbAxkLoe1s2DtbCjOAL9A6HyuFRBdRujQ3crlNBSUOsnW7y3m5neXs7eoggcv6sGkwR2QYz3TyOGAzLQDAVGyB/zskHoedB8NycMgMsk1O6B8moaCUi5QVF7DnR+u5PuNOZzTLYHHx/duenPSoRwOyFh6ICBK91nLo9pDh6HWWEwdhkJMRz3NVZ0wDQWlXMThMLy9aAdPzNtASKAfj43rzcjebU70TWHfati1CHb+AjsXQnmetS6s1YGA6DAU4ruBTefH8jkOBxgH+B3fhJkaCkq52JbsEv700a+szijikn6J/H1MTyKDD3Ox27EyBnI3OQPCGRTFzqHDgqOhTV9o3Qta9bbu47pYkwUpz+Kog4pCKMuG0iwozXE+dt72Py7LsW4XPQv9/++4fpSGglLNoKbOwUsLtvDCd1tICLfz1KWnMCw17uT/IGOgcJd1BLFrIexdDdnroa7KWu8XCPFdD4REq17QujeExJz8WtTBaiqgLBfKc637slzrKK+qGCqLrWHYq4qdt5IDt8piqClr/D1tARCWYN1CEyAs3rrvfhEknnpcZWooKNWMVmcU8scPV7E1p4xrT0/mnhHdCA70c+0PrauFvC3WxXL7VsO+dOtxaYNB/ULjIbyN89bKed/aug9zPg+NP+4mCa9SWw2VhdZf7oe7ryg48OVfngtleYf/YkfAHt7gFnHgcVDEgedBUQe+9MNaWY+Dok56P5KGglLNrLKmjn9+uZFpv2ynY3woz1zel77t3HCxWmkOZK2xQiJvM5RkWZ3YJfuspggO+T8vNisYQuMhJNa6hcZBSJx1pFH/2Lk8KMpqqmrOzm+HAxw1UFcDtVVQWwE1ldZ9bZX113ptpfN+//oKqC6F6jJr7u36x/tvpQfuK4ug5ijzcweEWk13obHW72P/7+U3z52/K3tEi+r70VBQyk0Wbsnlzx//SlZJFbed1Znbz+589Cuhm0tdrdVOXeIMiZK91pFFyd4DzR77/wo+2rwRfnZr3gm/wEbug6zHxlido6bOaj/f/9g4DnScmjpw1Fq1OWoPfPk7ap33NdZ2x0tsEBgOgSHW1KuBoRAYduBxQKh1IWFwlBV49ffRBx4HRYJ/4PHX0AJoKCjlRsWVNTw8Zx0zV2TQpVUY/xjbi0EdY91d1rGpq4Hy/AbNJXnWrbLQamqpq2pw77wdtKzaOpoQm3Wz+YH4NXhsO3idLcBqxrIFWEciv3nub937B1m3gGArePyDISDIuve3O5c71weGWcv0lF4NBaVagm/XZ/H3OWvJKKjgkv6J3DuyO/HhdneXpXxQU0OhhRzTKuWdzuneiq//eCaTz+rMZ7/u4Zynv+fdxTupO3QSH6VaCA0FpVwsONCPP1/QlS/vOoPeSZE8MDudcS//wq+7C91dmlK/oaGgVDPpFB/G/64fxAtX9mNfUSUXv/wL989eQ1F5jbtLU6qehoJSzUhEGH1KW769+0yuOz2F95fs4uynv2fG8gw8rX9PeScNBaXcIDwogAdH9+Cz24fRITaEP3/8K5e+uoiFW3M1HJRbaSgo5UY920Yy45bTeXJ8bzIKyrnqjSVMeH2xhoNyGz0lVakWorKmjulLd/Hy91vJLqliYEoMd52bypCOscc+b4NSh9DrFJTyUBoOyhU0FJTycBoO6mTSUFDKSzQWDrec2ZHhXRKw2TQcVNNoKCjlZfaHwys/bCWruIr2MSFMGtyeywe0IyrEswdrU66noaCUl6qpczB/7T7eWbiTpTvysfvbGNu3Lf83JJleiZHuLk+1UBoKSvmA9XuLeWfRTmavzKSipo7+7aO45vRkRvZqQ6C/nnGuDtBQUMqHFFXUMGN5Bu8u2sGOvHLiwgK5cmB7rhrUnjaRwe4uT7UAGgpK+SCHw/DTllzeWbiD7zZmAzC0Uxzj+iUyoldrQu067aav0lBQysftzi/n47TdzFqVye78CoID/LigZyvG9U9iaKdY/FvKbHCqWWgoKKUAMMaQtrOAWSsz+fzXPRRX1hIfbmfMKW0Z1y+Rnm0j9LoHH6ChoJT6jaraOhZsyOaTFZks2JhNTZ2hS6swxvVLYvQpbUiKDnF3icpFNBSUUkdUUFbN52v2MmtFBit2WRP+nJIUycjebRjVqw3tYzUgvImGglKqyXbmlTEvfR/z1uzl14wiAHq2jWBU7zaM7NWajvFhbq5QnSgNBaXUcdmdX86X6fuYm76Xlc4jiG6twxnVuw2jeremc0K4mytUx0NDQSl1wvYUVvBl+j7mpe8lbWcBxkDH+FDOSI3njC5xDEqJ1dNcPYSGglLqpMoqruTL9H18uyGbpdvzqKxxEOAn9G8fze9S4/hdajy9EiPx00H6WqQWEQoiMgJ4DvAD3jTGPHHI+luA24A6oBS4yRiz7kjvqaGglPtV1tSxfGcBP23O5afNOazdUwxAZHAAwzrHMSw1jmGd42gXo53VLYXbQ0FE/IBNwHlABrAMuLLhl76IRBhjip2PxwC3GmNGHOl9NRSUanlyS6v4ZUsuP23O5efNuewrrgSgXUwwg1JiGZQSw+COsSRFB+s1EW7S1FBwZWPgQGCLMWabs6DpwFigPhT2B4JTKOBZbVlKKQDiwuyM7ZvI2L6JGGPYkl3KT5tzWbI9j2/XZzFjeQYAbSODGJgSw6COVlCkxIVqSLQwrgyFRGB3g+cZwKBDNxKR24A/AYHA2S6sRynVDESE1FbhpLYK5/fDUnA4DJuzS1m6PY/F2/P5eUses1ftASA+3M6glBhOS46hd1IkPdpEEBTg5+Y98G1uP23AGPMS8JKIXAXcD1xz6DYichNwE0D79u2bt0Cl1Amx2YSurcPp2jqcq4ckY4xhW24ZS7fns2RbHku25/P56r0A+NmE1IQweiVG0jsxkl6JVlAEB2pQNBdX9ikMAR4yxlzgfH4vgDHm8cNsbwMKjDFHnCVE+xSU8i7GGPYVV7Imo4j0zCJWZ1r3uaXVANgEUhPCnUERQdfWEaS2CiM2NFCbno5BS+hTWAakikgKkAlcAVzVcAMRSTXGbHY+vRDYjFLKp4gIbSKDaRMZzPk9WwO/DYo1mUX8sCmHmSsy6l8XFRJAakIYnRPC6ZwQRmpCGKmtwmgdEaRhcQJcFgrGmFoRmQzMxzoldZoxZq2IPAKkGWPmAJNF5FygBiigkaYjpZTvOVxQZBVXsTm7hM1ZpWzOLmVrdinz0vdSWF5T/9owuz+dEsLo2iqsvgmqu/ZVNJlevKaU8mjGGPLKqtmcVcqWnFK2ZJWwObuUDftKyC+zmqD8bEKXVuH0Tozw2aBoCc1HSinlciJCXJiduDA7QzrF1i83xrCnyGqCWpNZyJrMYr5Zn81HaVYT1P5O7d6JkaS2CiMlLoyUuBDaxYRg9/edsDiUhoJSyiuJCIlRwSRGBTOi14EmqP1Bsb+v4rsN2Xy8/EBfhU0gMTrYConYEFLiQkmOCyUlLpTEqGCvn7FOQ0Ep5TMaCwqAovIatueVsT23lO255WzPLWNHbhkrdhZQWlVbv52fTWgVbqdtVDBtooJpGxlkPXbet40KJjokwKM7ujUUlFI+LzIkgL4hUfRtF3XQcmMMuaXV9SGxM7+MvYWV7CmqYHVGIfPTK6mucxz0mqAAG20jg0mKCaFddDDtY0JoH2M1S7WPDSEiKKA5d+2YaSgopdRhiAjx4Xbiw+0MTIn5zXqHw+rk3ltUwZ7CCvYUVrK3qILMwgoyCqzgaHhmFFin0taHREwIHWKsJqqO8WHEhbn/2gsNBaWUOk4224HQ6JMU1eg2RRU17M4vt24F5ezKL2dXfgXr9hTz1dp91NQdOAM0IsiflPgwOsWF0jE+lE7xYXSMD6NDbEiznSmloaCUUi4UGRxApPM02EPVOQx7CivYllvGtpxStuWUsS23lEXb8vhkZWb9diKQFB3Mn8/vyti+iS6tV0NBKaXcxM8mtHM2JZ3ZJf6gdWVVtWzPLTsoMOLC7C6vSUNBKaVaoFC7P70Oc4ThSt59wq1SSqljoqGglFKqnoaCUkqpehoKSiml6mkoKKWUqqehoJRSqp6GglJKqXoaCkoppep53MxrIpID7DzOl8cBuSexnJbA2/bJ2/YHvG+fvG1/wPv2qbH96WCMiW9s44Y8LhROhIikNWU6Ok/ibfvkbfsD3rdP3rY/4H37dCL7o81HSiml6mkoKKWUqudrofC6uwtwAW/bJ2/bH/C+ffK2/QHv26fj3h+f6lNQSil1ZL52pKCUUuoINBSUUkrV85lQEJERIrJRRLaIyBR313OiRGSHiKwRkVUikubueo6HiEwTkWwRSW+wLEZEvhaRzc77aHfWeCwOsz8PiUim83NaJSKj3FnjsRKRdiKyQETWichaEbnTudwjP6cj7I/Hfk4iEiQiS0XkV+c+PexcniIiS5zfeR+KSGCT3s8X+hRExA/YBJwHZADLgCuNMevcWtgJEJEdwABjjMdecCMiZwClwDvGmF7OZf8E8o0xTzjDO9oYc48762yqw+zPQ0CpMeZf7qzteIlIG6CNMWaFiIQDy4GLgWvxwM/pCPtzOR76OYmIAKHGmFIRCQB+Bu4E/gR8YoyZLiKvAr8aY1452vv5ypHCQGCLMWabMaYamA6MdXNNPs8Y8yOQf8jiscDbzsdvY/2H9QiH2R+PZozZa4xZ4XxcAqwHEvHQz+kI++OxjKXU+TTAeTPA2cAM5/Imf0a+EgqJwO4GzzPw8H8IWB/6VyKyXERucncxJ1ErY8xe5+N9QCt3FnOSTBaR1c7mJY9oZmmMiCQD/YAleMHndMj+gAd/TiLiJyKrgGzga2ArUGiMqXVu0uTvPF8JBW80zBjTHxgJ3OZsuvAqxmrb9PT2zVeATkBfYC/wtHvLOT4iEgbMBO4yxhQ3XOeJn1Mj++PRn5Mxps4Y0xdIwmoZ6Xa87+UroZAJtGvwPMm5zGMZYzKd99nALKx/CN4gy9nuu7/9N9vN9ZwQY0yW8z+sA3gDD/ycnO3UM4H3jDGfOBd77OfU2P54w+cEYIwpBBYAQ4AoEfF3rmryd56vhMIyINXZGx8IXAHMcXNNx01EQp2dZIhIKHA+kH7kV3mMOcA1zsfXAJ+6sZYTtv+L02kcHvY5OTsx3wLWG2OeabDKIz+nw+2PJ39OIhIvIlHOx8FYJ9SsxwqHS52bNfkz8omzjwCcp5j9G/ADphljHnVzScdNRDpiHR0A+APve+L+iMgHwHCsYX6zgL8Ds4GPgPZYQ6RfbozxiM7bw+zPcKwmCQPsAG5u0Bbf4onIMOAnYA3gcC6+D6sd3uM+pyPsz5V46OckIn2wOpL9sP7Q/8gY84jze2I6EAOsBCYZY6qO+n6+EgpKKaWOzleaj5RSSjWBhoJSSql6GgpKKaXqaSgopZSqp6GglFKqnoaCUs1IRIaLyOfurkOpw9FQUEopVU9DQalGiMgk5xj1q0TkNeeAY6Ui8qxzzPpvRSTeuW1fEVnsHExt1v7B1ESks4h84xznfoWIdHK+fZiIzBCRDSLynvMqW6VaBA0FpQ4hIt2BCcBQ5yBjdcBEIBRIM8b0BH7AumIZ4B3gHmNMH6wrZfcvfw94yRhzCnA61kBrYI3MeRfQA+gIDHX5TinVRP5H30Qpn3MOcCqwzPlHfDDWgG8O4EPnNv8DPhGRSCDKGPODc/nbwMfOsakSjTGzAIwxlQDO91tqjMlwPl8FJGNNjKKU22koKPVbArxtjLn3oIUiDxyy3fGOEdNw/Jk69P+hakG0+Uip3/oWuFREEqB+PuIOWP9f9o86eRXwszGmCCgQkd85l18N/OCc1StDRC52voddREKadS+UOg76F4pShzDGrBOR+7FmtrMBNcBtQBkw0LkuG6vfAaxhiV91fulvA65zLr8aeE1EHnG+x2XNuBtKHRcdJVWpJhKRUmNMmLvrUMqVtPlIKaVUPT1SUEopVU+PFJRSStXTUFBKKVVPQ0EppVQ9DQWllFL1NBSUUkrV+3/0QQtP1K+1XQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make test data......\n"
     ]
    }
   ],
   "source": [
    "# Make test data\n",
    "print('Make test data......')\n",
    "x_test_word = ratings_test.morphs.apply(split_word).tolist()\n",
    "x_test = encoding_and_padding(x_test_word, keyword_dict, max_seq=int(max_seq))\n",
    "y_test = np.asarray(ratings_test.label.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 20), (50000,))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'checkpoint/'\n",
    "model = load_model(model_path+'22-0.3604.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 14s 284us/step\n",
      "Loss: 0.36765167089939116 Accuracy: 0.8436\n"
     ]
    }
   ],
   "source": [
    "# prob = model.predict(x_test)\n",
    "\n",
    "[loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "print('Loss:', loss, 'Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8436\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "test_f1_score = f1_score(y_test, pred > 0.5)\n",
    "print('F1 Score:', test_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
